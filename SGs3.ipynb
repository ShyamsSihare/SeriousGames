{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229aa595-e32b-44a3-8b87-34d051ea6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm, poisson\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import networkx as nx\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input\n",
    "from collections import deque\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.size': 10,\n",
    "    'axes.labelsize': 11,\n",
    "    'axes.titlesize': 13,\n",
    "    'xtick.labelsize': 9,\n",
    "    'ytick.labelsize': 9,\n",
    "    'legend.fontsize': 10,\n",
    "    'figure.titlesize': 16,\n",
    "    'axes.linewidth': 1.2,\n",
    "    'grid.color': '#dddddd',\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.5,\n",
    "    'figure.dpi': 300,\n",
    "})\n",
    "\n",
    "\n",
    "N_SAMPLES = 3000 \n",
    "SAMPLING_RATE = 100 \n",
    "GAME_DURATION_SECONDS = N_SAMPLES / SAMPLING_RATE\n",
    "PLAYER_STATES = ['CALM', 'FOCUSED', 'FRUSTRATED', 'FATIGUED']\n",
    "STATE_TRANSITION_MATRIX = np.array([\n",
    "    [0.995, 0.003, 0.001, 0.001], # CALM\n",
    "    [0.002, 0.996, 0.001, 0.001], # FOCUSED\n",
    "    [0.005, 0.005, 0.985, 0.005], # FRUSTRATED\n",
    "    [0.010, 0.001, 0.001, 0.988]  # FATIGUED\n",
    "])\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. MODULE 1: DATA SIMULATION ENGINE\n",
    "# ==============================================================================\n",
    "class IoTSeriousGameSimulator:\n",
    "\n",
    "    def __init__(self, n_samples, sampling_rate, initial_state='CALM'):\n",
    "        self.n_samples = n_samples\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.numeric_time_vector = np.linspace(0, n_samples / sampling_rate, n_samples)\n",
    "        self.time_index = pd.to_timedelta(self.numeric_time_vector, unit='s')\n",
    "        self.initial_state = initial_state\n",
    "        self.player_states = PLAYER_STATES\n",
    "        self.transition_matrix = STATE_TRANSITION_MATRIX\n",
    "        self.state_map = {state: i for i, state in enumerate(self.player_states)}\n",
    "        self.ground_truth_states = []\n",
    "        self.simulated_data = pd.DataFrame(index=self.time_index)\n",
    "        self.simulated_data.index.name = 'Time'\n",
    "\n",
    "    def _simulate_ground_truth_states(self):\n",
    "\n",
    "        print(\"Simulating ground truth player states...\")\n",
    "        current_state_index = self.state_map[self.initial_state]\n",
    "        states = []\n",
    "        for _ in range(self.n_samples):\n",
    "            states.append(self.player_states[current_state_index])\n",
    "\n",
    "            current_state_index = np.random.choice(\n",
    "                len(self.player_states),\n",
    "                p=self.transition_matrix[current_state_index]\n",
    "            )\n",
    "        self.ground_truth_states = states\n",
    "        self.simulated_data['player_state'] = self.ground_truth_states\n",
    "        print(\"... Ground truth states simulation complete.\")\n",
    "        return self\n",
    "\n",
    "    def _generate_ecg_signal(self, state):\n",
    "\n",
    "        if state == 'CALM':\n",
    "            hr_mean, hr_std = 65, 2\n",
    "            noise_amp = 0.03\n",
    "        elif state == 'FOCUSED':\n",
    "            hr_mean, hr_std = 75, 3\n",
    "            noise_amp = 0.02\n",
    "        elif state == 'FRUSTRATED':\n",
    "            hr_mean, hr_std = 95, 5\n",
    "            noise_amp = 0.05\n",
    "        elif state == 'FATIGUED':\n",
    "            hr_mean, hr_std = 60, 4\n",
    "            noise_amp = 0.04\n",
    "        else:\n",
    "            hr_mean, hr_std = 70, 2\n",
    "            noise_amp = 0.03\n",
    "\n",
    "        heart_rate = np.random.normal(hr_mean, hr_std)\n",
    "        rr_interval = 60.0 / heart_rate\n",
    "        \n",
    "        beat_duration = rr_interval\n",
    "        beat_len = int(beat_duration * self.sampling_rate)\n",
    "\n",
    "\n",
    "        if beat_len == 0:\n",
    "            return np.array([]), noise_amp, heart_rate\n",
    "            \n",
    "        beat = np.zeros(beat_len)\n",
    "\n",
    "\n",
    "        p_amp, q_amp, r_amp, s_amp, t_amp = 0.1, -0.1, 1.0, -0.15, 0.2\n",
    "\n",
    "\n",
    "        p_start_frac, p_dur_frac = 0.1, 0.12\n",
    "        qrs_start_frac, qrs_dur_frac = 0.25, 0.1\n",
    "        t_start_frac, t_dur_frac = 0.45, 0.18\n",
    "\n",
    "\n",
    "        p_start = int(p_start_frac * beat_len)\n",
    "        p_len = int(p_dur_frac * beat_len)\n",
    "\n",
    "        qrs_start = int(qrs_start_frac * beat_len)\n",
    "        qrs_len = int(qrs_dur_frac * beat_len)\n",
    "\n",
    "        t_start = int(t_start_frac * beat_len)\n",
    "        t_len = int(t_dur_frac * beat_len)\n",
    "\n",
    "        if p_start + p_len < beat_len and p_len > 0:\n",
    "            p_x = np.linspace(-np.pi/2, np.pi/2, p_len)\n",
    "            p_wave = p_amp * np.cos(p_x)\n",
    "            beat[p_start:p_start+p_len] = p_wave\n",
    "\n",
    "\n",
    "        if qrs_start + qrs_len < beat_len and qrs_len > 0:\n",
    "\n",
    "            q_len = int(0.25 * qrs_len)\n",
    "            r_len = int(0.5 * qrs_len)\n",
    "            s_len = qrs_len - q_len - r_len\n",
    "\n",
    "            if q_len > 0:\n",
    "                q_wave = np.linspace(0, q_amp, q_len)\n",
    "                beat[qrs_start : qrs_start+q_len] = q_wave\n",
    "            if r_len > 0:\n",
    "                r_wave_up = np.linspace(q_amp, r_amp, r_len // 2 if r_len > 1 else 1)\n",
    "                r_wave_down = np.linspace(r_amp, s_amp, r_len - (r_len // 2) if r_len > 1 else 0)\n",
    "                r_wave = np.concatenate([r_wave_up, r_wave_down])\n",
    "                beat[qrs_start+q_len : qrs_start+q_len+r_len] = r_wave\n",
    "            if s_len > 0:\n",
    "                s_wave = np.linspace(s_amp, 0, s_len)\n",
    "                beat[qrs_start+q_len+r_len : qrs_start+q_len+r_len+s_len] = s_wave\n",
    "\n",
    "\n",
    "        if t_start + t_len < beat_len and t_len > 0:\n",
    "            t_x = np.linspace(-np.pi/2, np.pi/2, t_len)\n",
    "            t_wave = t_amp * np.cos(t_x)\n",
    "            beat[t_start:t_start+t_len] = t_wave\n",
    "\n",
    "        return beat, noise_amp, heart_rate\n",
    "\n",
    "    def simulate_ecg(self):\n",
    "\n",
    "        print(\"Simulating ECG data...\")\n",
    "        ecg_signal = np.array([])\n",
    "        heart_rates = []\n",
    "        current_sample = 0\n",
    "        while len(ecg_signal) < self.n_samples:\n",
    "            state = self.ground_truth_states[min(len(ecg_signal), self.n_samples-1)]\n",
    "            beat, noise_amp, hr = self._generate_ecg_signal(state)\n",
    "            ecg_signal = np.append(ecg_signal, beat)\n",
    "            heart_rates.extend([hr] * len(beat))\n",
    "        \n",
    "        ecg_signal = ecg_signal[:self.n_samples]\n",
    "        heart_rates = heart_rates[:self.n_samples]\n",
    "        \n",
    "\n",
    "        baseline_wander = 0.1 * np.sin(2 * np.pi * 0.1 * self.numeric_time_vector)\n",
    "\n",
    "        noise_amps = [self._generate_ecg_signal(s)[1] for s in self.ground_truth_states]\n",
    "        avg_noise_amp = np.mean(noise_amps) if noise_amps else 0.03\n",
    "        noise = np.random.normal(0, avg_noise_amp, self.n_samples)\n",
    "        \n",
    "        self.simulated_data['ecg'] = ecg_signal + baseline_wander + noise\n",
    "        self.simulated_data['heart_rate'] = heart_rates\n",
    "        print(\"... ECG data simulation complete.\")\n",
    "        return self\n",
    "\n",
    "    def _generate_accelerometer_signal(self, state):\n",
    "\n",
    "        if state == 'CALM':\n",
    "            base_amp, freq, noise_std = 0.05, 0.2, 0.01\n",
    "        elif state == 'FOCUSED':\n",
    "            base_amp, freq, noise_std = 0.1, 0.5, 0.02\n",
    "        elif state == 'FRUSTRATED':\n",
    "            base_amp, freq, noise_std = 0.8, 2.0, 0.1\n",
    "        elif state == 'FATIGUED':\n",
    "            base_amp, freq, noise_std = 0.02, 0.1, 0.01\n",
    "        else:\n",
    "            base_amp, freq, noise_std = 0.1, 0.5, 0.02\n",
    "\n",
    "\n",
    "        x = base_amp * np.sin(2 * np.pi * freq * self.numeric_time_vector + np.pi/4) + np.random.normal(0, noise_std, self.n_samples)\n",
    "        y = base_amp * np.cos(2 * np.pi * freq * self.numeric_time_vector) + np.random.normal(0, noise_std, self.n_samples)\n",
    "        z = base_amp/2 * np.sin(2 * np.pi * freq/2 * self.numeric_time_vector) + np.random.normal(0, noise_std, self.n_samples)\n",
    "        return x, y, z\n",
    "\n",
    "    def simulate_motion_sensors(self):\n",
    "\n",
    "        print(\"Simulating motion sensor data...\")\n",
    "        acc_x, acc_y, acc_z = np.zeros(self.n_samples), np.zeros(self.n_samples), np.zeros(self.n_samples)\n",
    "        \n",
    "        for state in self.player_states:\n",
    "            mask = self.simulated_data['player_state'] == state\n",
    "            x, y, z = self._generate_accelerometer_signal(state)\n",
    "            acc_x[mask] = x[mask]\n",
    "            acc_y[mask] = y[mask]\n",
    "            acc_z[mask] = z[mask]\n",
    "            \n",
    "        self.simulated_data['acc_x'] = acc_x\n",
    "        self.simulated_data['acc_y'] = acc_y\n",
    "        self.simulated_data['acc_z'] = acc_z\n",
    "        \n",
    "\n",
    "        self.simulated_data['gyro_x'] = np.gradient(acc_x, 1/self.sampling_rate)\n",
    "        self.simulated_data['gyro_y'] = np.gradient(acc_y, 1/self.sampling_rate)\n",
    "        self.simulated_data['gyro_z'] = np.gradient(acc_z, 1/self.sampling_rate)\n",
    "        print(\"... Motion sensor data simulation complete.\")\n",
    "        return self\n",
    "\n",
    "    def simulate_environmental_sensors(self):\n",
    "\n",
    "        print(\"Simulating environmental sensor data...\")\n",
    "\n",
    "        temp_start, temp_end = 21.5, 23.0\n",
    "        temperature = np.linspace(temp_start, temp_end, self.n_samples) + np.random.normal(0, 0.1, self.n_samples)\n",
    "        \n",
    "\n",
    "        humidity_start, humidity_end = 55.0, 52.0\n",
    "        humidity = np.linspace(humidity_start, humidity_end, self.n_samples) + np.random.normal(0, 0.5, self.n_samples)\n",
    "        \n",
    "        self.simulated_data['temperature'] = temperature\n",
    "        self.simulated_data['humidity'] = humidity\n",
    "        print(\"... Environmental sensor simulation complete.\")\n",
    "        return self\n",
    "\n",
    "    def simulate_game_events(self):\n",
    "\n",
    "        print(\"Simulating game events...\")\n",
    "        scores = []\n",
    "        actions = []\n",
    "        current_score = 0\n",
    "        \n",
    "        for i in range(self.n_samples):\n",
    "            state = self.ground_truth_states[i]\n",
    "            \n",
    "\n",
    "            if state == 'FOCUSED':\n",
    "                action_prob = 0.1\n",
    "                score_change = np.random.choice([10, 20], p=[0.7, 0.3])\n",
    "            elif state == 'FRUSTRATED':\n",
    "                action_prob = 0.3\n",
    "                score_change = np.random.choice([-5, -10], p=[0.8, 0.2])\n",
    "            else:\n",
    "                action_prob = 0.02\n",
    "                score_change = 1\n",
    "            \n",
    "            if np.random.rand() < action_prob:\n",
    "                current_score += score_change\n",
    "                actions.append(score_change)\n",
    "            else:\n",
    "                actions.append(0)\n",
    "            \n",
    "            scores.append(current_score)\n",
    "            \n",
    "        self.simulated_data['game_score'] = scores\n",
    "        self.simulated_data['last_action'] = actions\n",
    "        print(\"... Game events simulation complete.\")\n",
    "        return self\n",
    "\n",
    "    def run_simulation(self):\n",
    "\n",
    "        start_time = time.time()\n",
    "        print(\"--- Starting Full Data Simulation ---\")\n",
    "        self._simulate_ground_truth_states()\n",
    "        self.simulate_ecg()\n",
    "        self.simulate_motion_sensors()\n",
    "        self.simulate_environmental_sensors()\n",
    "        self.simulate_game_events()\n",
    "        end_time = time.time()\n",
    "        print(f\"--- Full Simulation Finished in {end_time - start_time:.2f} seconds ---\")\n",
    "        return self.simulated_data.copy()\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. MODULE 2: STATISTICAL ANALYSIS AND FOUNDATIONAL PLOTS\n",
    "# ==============================================================================\n",
    "class FoundationalAnalysis:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.analysis_results = {}\n",
    "\n",
    "    def calculate_correlation_matrix(self):\n",
    "\n",
    "        print(\"Calculating correlation matrix...\")\n",
    "        features = ['heart_rate', 'acc_x', 'acc_y', 'acc_z', 'temperature', 'humidity', 'game_score']\n",
    "        self.correlation_matrix = self.data[features].corr()\n",
    "        self.analysis_results['correlation_matrix'] = self.correlation_matrix\n",
    "        print(\"... Correlation matrix calculated.\")\n",
    "        return self\n",
    "\n",
    "    def plot_correlation_heatmap(self, ax):\n",
    "\n",
    "        print(\"Plotting correlation heatmap...\")\n",
    "        if 'correlation_matrix' not in self.analysis_results:\n",
    "            self.calculate_correlation_matrix()\n",
    "            \n",
    "        sns.heatmap(self.correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', ax=ax,\n",
    "                    cbar_kws={'label': 'Correlation Coefficient'})\n",
    "        ax.set_title('Correlation Matrix of IoT Sensor Data')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        ax.tick_params(axis='y', rotation=0)\n",
    "        print(\"... Heatmap plotted.\")\n",
    "\n",
    "    def perform_pca(self):\n",
    "\n",
    "        print(\"Performing PCA on motion data...\")\n",
    "        motion_features = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "        pca_data = self.data[motion_features].dropna()\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(pca_data)\n",
    "        \n",
    "        self.pca = PCA(n_components=2)\n",
    "        self.principal_components = self.pca.fit_transform(scaled_data)\n",
    "        \n",
    "        self.pca_df = pd.DataFrame(data=self.principal_components, columns=['PC1', 'PC2'])\n",
    "\n",
    "        self.pca_df['player_state'] = self.data.loc[pca_data.index, 'player_state'].values\n",
    "        \n",
    "        self.analysis_results['pca_explained_variance'] = self.pca.explained_variance_ratio_\n",
    "        self.analysis_results['pca_df'] = self.pca_df\n",
    "        print(f\"... PCA complete. Explained variance: {self.pca.explained_variance_ratio_}\")\n",
    "        return self\n",
    "\n",
    "    def plot_pca(self, ax):\n",
    "\n",
    "        print(\"Plotting PCA results...\")\n",
    "        if 'pca_df' not in self.analysis_results:\n",
    "            self.perform_pca()\n",
    "            \n",
    "        targets = self.pca_df['player_state'].unique()\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(targets)))\n",
    "        \n",
    "        for target, color in zip(targets, colors):\n",
    "            indices_to_keep = self.pca_df['player_state'] == target\n",
    "            ax.scatter(self.pca_df.loc[indices_to_keep, 'PC1'],\n",
    "                       self.pca_df.loc[indices_to_keep, 'PC2'],\n",
    "                       c=[color], s=50, alpha=0.6, label=target)\n",
    "                       \n",
    "        ax.set_xlabel(f'Principal Component 1 ({self.analysis_results[\"pca_explained_variance\"][0]:.1%})')\n",
    "        ax.set_ylabel(f'Principal Component 2 ({self.analysis_results[\"pca_explained_variance\"][1]:.1%})')\n",
    "        ax.set_title('PCA of Motion Sensor Data by Player State')\n",
    "        ax.legend(title='Player State')\n",
    "        ax.grid(True)\n",
    "        print(\"... PCA plot complete.\")\n",
    "\n",
    "    def create_sensor_network_graph(self):\n",
    "\n",
    "        print(\"Creating sensor network graph...\")\n",
    "        self.G = nx.Graph()\n",
    "        sensors = ['ECG', 'Accelerometer', 'Gyroscope', 'Temp/Humid', 'GameLogic']\n",
    "        self.G.add_nodes_from(sensors)\n",
    "        \n",
    "\n",
    "        self.G.add_edges_from([\n",
    "            ('ECG', 'GameLogic'),\n",
    "            ('Accelerometer', 'Gyroscope'),\n",
    "            ('Accelerometer', 'GameLogic'),\n",
    "            ('Temp/Humid', 'GameLogic')\n",
    "        ])\n",
    "        \n",
    "        self.analysis_results['sensor_network_graph'] = self.G\n",
    "        print(\"... Sensor network graph created.\")\n",
    "        return self\n",
    "\n",
    "    def plot_sensor_network(self, ax):\n",
    "\n",
    "        print(\"Plotting sensor network...\")\n",
    "        if 'sensor_network_graph' not in self.analysis_results:\n",
    "            self.create_sensor_network_graph()\n",
    "            \n",
    "        pos = nx.spring_layout(self.G, seed=42)\n",
    "        nx.draw(self.G, pos, with_labels=True, node_color='skyblue', node_size=3000,\n",
    "                edge_color='gray', width=2.0, font_size=10, font_weight='bold', ax=ax)\n",
    "        ax.set_title('Conceptual IoT Sensor Network')\n",
    "        print(\"... Sensor network plot complete.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. MODULE 3: TIME SERIES ANALYSIS AND FORECASTING\n",
    "# ==============================================================================\n",
    "class TimeSeriesAnalysis:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data['heart_rate'].resample('1S').mean().dropna()\n",
    "        self.train_data, self.test_data = train_test_split(self.data, test_size=0.2, shuffle=False)\n",
    "        self.analysis_results = {}\n",
    "\n",
    "    def train_arima_model(self):\n",
    "\n",
    "        print(\"Training ARIMA model...\")\n",
    "        history = [x for x in self.train_data]\n",
    "        predictions = []\n",
    "        for t in range(len(self.test_data)):\n",
    "            model = ARIMA(history, order=(5,1,0))\n",
    "            model_fit = model.fit()\n",
    "            output = model_fit.forecast()\n",
    "            yhat = output[0]\n",
    "            predictions.append(yhat)\n",
    "            obs = self.test_data.iloc[t]\n",
    "            history.append(obs)\n",
    "        self.analysis_results['arima_predictions'] = predictions\n",
    "        print(\"... ARIMA training and prediction complete.\")\n",
    "        return self\n",
    "\n",
    "    def _create_lstm_dataset(self, dataset, look_back=1):\n",
    "\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset) - look_back - 1):\n",
    "            a = dataset[i:(i + look_back), 0]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + look_back, 0])\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    def train_lstm_model(self):\n",
    "\n",
    "        print(\"Training LSTM model...\")\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(self.data.values.reshape(-1, 1))\n",
    "\n",
    "        train_size = int(len(dataset) * 0.8)\n",
    "        train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
    "        \n",
    "        look_back = 3\n",
    "        trainX, trainY = self._create_lstm_dataset(train, look_back)\n",
    "        testX, testY = self._create_lstm_dataset(test, look_back)\n",
    "        \n",
    "        trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "        testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n",
    "        model = Sequential([\n",
    "            Input(shape=(look_back, 1)),\n",
    "            LSTM(4, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=0)\n",
    "        \n",
    "        trainPredict = model.predict(trainX, verbose=0)\n",
    "        testPredict = model.predict(testX, verbose=0)\n",
    "        \n",
    "\n",
    "        trainPredict = scaler.inverse_transform(trainPredict)\n",
    "        testPredict = scaler.inverse_transform(testPredict)\n",
    "        \n",
    "        self.analysis_results['lstm_predictions'] = testPredict.flatten()\n",
    "        self.analysis_results['lstm_test_y'] = scaler.inverse_transform([testY]).flatten()\n",
    "        print(\"... LSTM training and prediction complete.\")\n",
    "        return self\n",
    "\n",
    "    def plot_forecasts(self, ax):\n",
    "  \n",
    "        print(\"Plotting time series forecasts...\")\n",
    "        if 'arima_predictions' not in self.analysis_results:\n",
    "            self.train_arima_model()\n",
    "        if 'lstm_predictions' not in self.analysis_results:\n",
    "            self.train_lstm_model()\n",
    "            \n",
    "        test_indices = self.test_data.index\n",
    "        \n",
    "\n",
    "        ax.plot(self.data.index.total_seconds(), self.data.values, label='Original Heart Rate', color='black', alpha=0.3)\n",
    "        ax.plot(test_indices.total_seconds(), self.test_data.values, label='Test Data (Actual)', color='blue', linewidth=2)\n",
    "        \n",
    "\n",
    "        if len(test_indices) == len(self.analysis_results['arima_predictions']):\n",
    "            ax.plot(test_indices.total_seconds(), self.analysis_results['arima_predictions'], label='ARIMA Forecast', color='red', linestyle='--')\n",
    "        \n",
    "\n",
    "        lstm_start_index = len(test_indices) - len(self.analysis_results['lstm_predictions'])\n",
    "        if lstm_start_index >= 0:\n",
    "            ax.plot(test_indices[lstm_start_index:].total_seconds(), self.analysis_results['lstm_predictions'], label='LSTM Forecast', color='green', linestyle='-.')\n",
    "        \n",
    "        ax.set_title('Heart Rate Forecasting: ARIMA vs. LSTM')\n",
    "        ax.set_xlabel('Time (s)') \n",
    "        ax.set_ylabel('Heart Rate (BPM)')\n",
    "        ax.legend()\n",
    "        \n",
    "\n",
    "        start_lim = self.data.index[int(len(self.data)*0.75)].total_seconds()\n",
    "        end_lim = self.data.index[-1].total_seconds()\n",
    "        ax.set_xlim(start_lim, end_lim)\n",
    "        \n",
    "        print(\"... Forecast plot complete.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. MODULE 4: REINFORCEMENT LEARNING FOR ADAPTIVE DIFFICULTY\n",
    "# ==============================================================================\n",
    "class GameEnvironment:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.state_size = 2\n",
    "        self.action_size = 3 \n",
    "        self.player_skill = np.random.uniform(0.3, 0.7)\n",
    "        self.difficulty = 0.5\n",
    "        self.max_steps = 100\n",
    "        self.current_step = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.player_skill = np.random.uniform(0.3, 0.7)\n",
    "        self.difficulty = 0.5\n",
    "        self.current_step = 0\n",
    "        return np.array([self.player_skill, self.difficulty])\n",
    "\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "        \n",
    "\n",
    "        if action == 0: \n",
    "            self.difficulty = max(0.1, self.difficulty - 0.05)\n",
    "        elif action == 2: \n",
    "            self.difficulty = min(1.0, self.difficulty + 0.05)\n",
    "            \n",
    "\n",
    "        performance = np.random.normal(self.player_skill, 0.1)\n",
    "        challenge_gap = self.difficulty - performance\n",
    "        \n",
    "\n",
    "        reward = np.exp(-10 * (challenge_gap**2))\n",
    "        \n",
    "\n",
    "        if abs(challenge_gap) > 0.2:\n",
    "            reward -= 0.2\n",
    "            \n",
    "\n",
    "        if challenge_gap > -0.1: \n",
    "            self.player_skill += 0.005 * (1 - self.player_skill)\n",
    "\n",
    "        done = self.current_step >= self.max_steps\n",
    "        next_state = np.array([self.player_skill, self.difficulty])\n",
    "        \n",
    "        return next_state, reward, done\n",
    "\n",
    "class DQNAgent:\n",
    "\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    \n",
    "        self.epsilon = 1.0 \n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "\n",
    "        model = Sequential([\n",
    "            Input(shape=(self.state_size,)),\n",
    "            Dense(24, activation='relu'),\n",
    "            Dense(24, activation='relu'),\n",
    "            Dense(self.action_size, activation='linear')\n",
    "        ])\n",
    "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state, verbose=0)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma * np.amax(self.model.predict(next_state, verbose=0)[0]))\n",
    "            target_f = self.model.predict(state, verbose=0)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "class RLAnalysis:\n",
    "\n",
    "    def __init__(self, episodes=100):\n",
    "        self.episodes = episodes\n",
    "        self.env = GameEnvironment()\n",
    "        self.agent = DQNAgent(self.env.state_size, self.env.action_size)\n",
    "        self.analysis_results = {}\n",
    "\n",
    "    def run_training(self):\n",
    "\n",
    "        print(\"Running DQN training for adaptive difficulty...\")\n",
    "        all_rewards = []\n",
    "        batch_size = 32\n",
    "        \n",
    "        for e in range(self.episodes):\n",
    "            state = self.env.reset()\n",
    "            state = np.reshape(state, [1, self.env.state_size])\n",
    "            episode_reward = 0\n",
    "            for time_step in range(self.env.max_steps):\n",
    "                action = self.agent.act(state)\n",
    "                next_state, reward, done = self.env.step(action)\n",
    "                episode_reward += reward\n",
    "                next_state = np.reshape(next_state, [1, self.env.state_size])\n",
    "                self.agent.remember(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                if done:\n",
    "                    break\n",
    "            all_rewards.append(episode_reward)\n",
    "            self.agent.replay(batch_size)\n",
    "            if (e + 1) % 20 == 0:\n",
    "                print(f\"Episode {e+1}/{self.episodes}, Score: {episode_reward:.2f}, Epsilon: {self.agent.epsilon:.2f}\")\n",
    "        \n",
    "        self.analysis_results['rl_rewards'] = all_rewards\n",
    "        print(\"... DQN training complete.\")\n",
    "        return self\n",
    "\n",
    "    def plot_rl_training(self, ax):\n",
    "\n",
    "        print(\"Plotting RL training results...\")\n",
    "        if 'rl_rewards' not in self.analysis_results:\n",
    "            self.run_training()\n",
    "        \n",
    "        rewards = self.analysis_results['rl_rewards']\n",
    "        ax.plot(rewards, label='Reward per Episode', color='purple')\n",
    "        \n",
    "\n",
    "        moving_avg = pd.Series(rewards).rolling(window=10).mean()\n",
    "        ax.plot(moving_avg, label='10-Episode Moving Average', color='orange', linewidth=2)\n",
    "        \n",
    "        ax.set_title('DQN Agent Training for Adaptive Difficulty')\n",
    "        ax.set_xlabel('Episode')\n",
    "        ax.set_ylabel('Total Reward')\n",
    "        ax.legend()\n",
    "        print(\"... RL plot complete.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. MODULE 5: MULTI-OBJECTIVE OPTIMIZATION FOR RESOURCE ALLOCATION\n",
    "# ==============================================================================\n",
    "class MOOAnalysis:\n",
    "\n",
    "    def __init__(self, n_population=100, n_generations=50):\n",
    "        self.n_population = n_population\n",
    "        self.n_generations = n_generations\n",
    "        self.n_variables = 2 # e.g., [CPU_allocation, Bandwidth_allocation]\n",
    "        self.bounds = [(0.1, 1.0), (0.1, 1.0)]\n",
    "        self.analysis_results = {}\n",
    "\n",
    "    def _objective_function_1(self, x):\n",
    "\n",
    "\n",
    "        return 1 / (x[0]**2 + x[1]) + np.random.normal(0, 0.05)\n",
    "\n",
    "    def _objective_function_2(self, x):\n",
    "\n",
    "\n",
    "        return (x[0]**1.5) + (x[1] * 0.5) + np.random.normal(0, 0.05)\n",
    "\n",
    "    def _dominates(self, p1, p2):\n",
    "\n",
    "        scores1 = [self._objective_function_1(p1), self._objective_function_2(p1)]\n",
    "        scores2 = [self._objective_function_1(p2), self._objective_function_2(p2)]\n",
    "        return all(s1 <= s2 for s1, s2 in zip(scores1, scores2)) and any(s1 < s2 for s1, s2 in zip(scores1, scores2))\n",
    "\n",
    "    def run_genetic_algorithm(self):\n",
    "\n",
    "        print(\"Running Genetic Algorithm for MOO...\")\n",
    "\n",
    "        population = []\n",
    "        for _ in range(self.n_population):\n",
    "            population.append([random.uniform(self.bounds[i][0], self.bounds[i][1]) for i in range(self.n_variables)])\n",
    "            \n",
    "        for gen in range(self.n_generations):\n",
    "\n",
    "            fitness_scores = [[self._objective_function_1(p), self._objective_function_2(p)] for p in population]\n",
    "            \n",
    "\n",
    "            fronts = []\n",
    "            dominated_by = {i: set() for i in range(self.n_population)}\n",
    "            dominates_over = {i: set() for i in range(self.n_population)}\n",
    "            \n",
    "            for i in range(self.n_population):\n",
    "                for j in range(i + 1, self.n_population):\n",
    "                    if self._dominates(population[i], population[j]):\n",
    "                        dominates_over[i].add(j)\n",
    "                        dominated_by[j].add(i)\n",
    "                    elif self._dominates(population[j], population[i]):\n",
    "                        dominates_over[j].add(i)\n",
    "                        dominated_by[i].add(j)\n",
    "            \n",
    "            current_front = []\n",
    "            for i in range(self.n_population):\n",
    "                if not dominated_by[i]:\n",
    "                    current_front.append(i)\n",
    "            \n",
    "            fronts.append(current_front)\n",
    "\n",
    "            offspring = []\n",
    "            for _ in range(self.n_population):\n",
    "\n",
    "                p1_idx, p2_idx = random.sample(range(self.n_population), 2)\n",
    "                parent1 = population[p1_idx] if fitness_scores[p1_idx][0] < fitness_scores[p2_idx][0] else population[p2_idx]\n",
    "                p3_idx, p4_idx = random.sample(range(self.n_population), 2)\n",
    "                parent2 = population[p3_idx] if fitness_scores[p3_idx][1] < fitness_scores[p4_idx][1] else population[p4_idx]\n",
    "                \n",
    "\n",
    "                child = [(p1_val + p2_val) / 2 for p1_val, p2_val in zip(parent1, parent2)]\n",
    "                \n",
    "\n",
    "                if random.random() < 0.1:\n",
    "                    idx_to_mutate = random.randrange(self.n_variables)\n",
    "                    child[idx_to_mutate] += random.normalvariate(0, 0.1)\n",
    "                    child[idx_to_mutate] = max(self.bounds[idx_to_mutate][0], min(child[idx_to_mutate], self.bounds[idx_to_mutate][1]))\n",
    "                \n",
    "                offspring.append(child)\n",
    "            \n",
    "            population = offspring \n",
    "\n",
    "\n",
    "        final_fitness = [[self._objective_function_1(p), self._objective_function_2(p)] for p in population]\n",
    "        final_dominated_by = {i: set() for i in range(self.n_population)}\n",
    "        for i in range(self.n_population):\n",
    "            for j in range(i + 1, self.n_population):\n",
    "                if all(s1 <= s2 for s1, s2 in zip(final_fitness[i], final_fitness[j])) and any(s1 < s2 for s1, s2 in zip(final_fitness[i], final_fitness[j])):\n",
    "                    final_dominated_by[j].add(i)\n",
    "                elif all(s2 <= s1 for s1, s2 in zip(final_fitness[i], final_fitness[j])) and any(s2 < s1 for s1, s2 in zip(final_fitness[i], final_fitness[j])):\n",
    "                    final_dominated_by[i].add(j)\n",
    "        \n",
    "        pareto_front_indices = [i for i, dominated_set in final_dominated_by.items() if not dominated_set]\n",
    "        self.analysis_results['pareto_front'] = np.array([final_fitness[i] for i in pareto_front_indices])\n",
    "        print(\"... Genetic Algorithm complete.\")\n",
    "        return self\n",
    "\n",
    "    def plot_pareto_front(self, ax):\n",
    "\n",
    "        print(\"Plotting Pareto front...\")\n",
    "        if 'pareto_front' not in self.analysis_results:\n",
    "            self.run_genetic_algorithm()\n",
    "            \n",
    "        pareto_front = self.analysis_results.get('pareto_front', np.array([]))\n",
    "        if pareto_front.size == 0:\n",
    "            print(\"... Pareto front is empty, skipping plot.\")\n",
    "            return\n",
    "\n",
    "\n",
    "        pareto_front = pareto_front[pareto_front[:, 0].argsort()]\n",
    "        \n",
    "        ax.scatter(pareto_front[:, 0], pareto_front[:, 1], c='blue', s=50, label='Pareto Optimal Solutions')\n",
    "        ax.plot(pareto_front[:, 0], pareto_front[:, 1], color='blue', linestyle='--', alpha=0.7)\n",
    "        ax.set_title('Pareto Front for Resource Allocation')\n",
    "        ax.set_xlabel('Objective 1: Latency (Lower is Better)')\n",
    "        ax.set_ylabel('Objective 2: Energy (Lower is Better)')\n",
    "        ax.legend()\n",
    "        print(\"... Pareto front plot complete.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 7. MODULE 6: STOCHASTIC PROCESSES (HIDDEN MARKOV MODELS)\n",
    "# ==============================================================================\n",
    "class HMMAnalysis:\n",
    "\n",
    "    def __init__(self, data):\n",
    "\n",
    "        self.observations = data['heart_rate'].values\n",
    "        self.states = PLAYER_STATES\n",
    "        self.state_map = {state: i for i, state in enumerate(self.states)}\n",
    "        \n",
    "\n",
    "        self.emission_params = {\n",
    "            'CALM': {'mean': 65, 'std': 5},\n",
    "            'FOCUSED': {'mean': 75, 'std': 5},\n",
    "            'FRUSTRATED': {'mean': 95, 'std': 8},\n",
    "            'FATIGUED': {'mean': 60, 'std': 6}\n",
    "        }\n",
    "\n",
    "        self.transition_matrix = STATE_TRANSITION_MATRIX\n",
    "        \n",
    "\n",
    "        self.initial_probs = np.array([0.7, 0.1, 0.1, 0.1])\n",
    "        \n",
    "        self.analysis_results = {}\n",
    "\n",
    "    def _get_emission_prob(self, obs, state):\n",
    "\n",
    "        params = self.emission_params[state]\n",
    "        return norm.pdf(obs, loc=params['mean'], scale=params['std'])\n",
    "\n",
    "    def run_viterbi_algorithm(self):\n",
    "\n",
    "        print(\"Running Viterbi algorithm for HMM state inference...\")\n",
    "        n_obs = len(self.observations)\n",
    "        n_states = len(self.states)\n",
    "\n",
    "        viterbi_matrix = np.zeros((n_obs, n_states))\n",
    "\n",
    "        backpointer_matrix = np.zeros((n_obs, n_states), dtype=int)\n",
    "        \n",
    "\n",
    "        for s_idx, state in enumerate(self.states):\n",
    "            emission_prob = self._get_emission_prob(self.observations[0], state)\n",
    "            viterbi_matrix[0, s_idx] = np.log(self.initial_probs[s_idx] + 1e-10) + np.log(emission_prob + 1e-10)\n",
    "            \n",
    "\n",
    "        for t in range(1, n_obs):\n",
    "            for s_idx, state in enumerate(self.states):\n",
    "                max_prob = -np.inf\n",
    "                max_state = 0\n",
    "                for prev_s_idx, prev_state in enumerate(self.states):\n",
    "                    prob = viterbi_matrix[t-1, prev_s_idx] + np.log(self.transition_matrix[prev_s_idx, s_idx] + 1e-10)\n",
    "                    if prob > max_prob:\n",
    "                        max_prob = prob\n",
    "                        max_state = prev_s_idx\n",
    "                \n",
    "                emission_prob = self._get_emission_prob(self.observations[t], state)\n",
    "                viterbi_matrix[t, s_idx] = max_prob + np.log(emission_prob + 1e-10)\n",
    "                backpointer_matrix[t, s_idx] = max_state\n",
    "                \n",
    "\n",
    "        best_path_prob = np.max(viterbi_matrix[n_obs-1, :])\n",
    "        best_last_state = np.argmax(viterbi_matrix[n_obs-1, :])\n",
    "        \n",
    "\n",
    "        best_path = [best_last_state]\n",
    "        for t in range(n_obs - 1, 0, -1):\n",
    "            best_last_state = backpointer_matrix[t, best_last_state]\n",
    "            best_path.insert(0, best_last_state)\n",
    "            \n",
    "        inferred_states = [self.states[i] for i in best_path]\n",
    "        self.analysis_results['inferred_states'] = inferred_states\n",
    "        print(\"... Viterbi algorithm complete.\")\n",
    "        return self\n",
    "\n",
    "    def plot_inferred_states(self, ax, ground_truth_states):\n",
    "\n",
    "        print(\"Plotting HMM inferred states...\")\n",
    "        if 'inferred_states' not in self.analysis_results:\n",
    "            self.run_viterbi_algorithm()\n",
    "            \n",
    "\n",
    "        state_to_num = {state: i for i, state in enumerate(self.states)}\n",
    "        gt_numeric = [state_to_num[s] for s in ground_truth_states]\n",
    "        inferred_numeric = [state_to_num[s] for s in self.analysis_results['inferred_states']]\n",
    "        \n",
    "        time_vec = np.arange(len(gt_numeric))\n",
    "        \n",
    "        ax.plot(time_vec, gt_numeric, label='Ground Truth State', color='black', linewidth=2.5, alpha=0.7)\n",
    "        ax.plot(time_vec, inferred_numeric, label='HMM Inferred State', color='red', linestyle='--', alpha=0.8)\n",
    "        \n",
    "        ax.set_yticks(list(state_to_num.values()))\n",
    "        ax.set_yticklabels(list(state_to_num.keys()))\n",
    "        ax.set_title('Player State Inference using HMM (Viterbi)')\n",
    "        ax.set_xlabel('Time Steps')\n",
    "        ax.set_ylabel('Player State')\n",
    "        ax.legend()\n",
    "        ax.set_ylim(-0.5, len(self.states) - 0.5)\n",
    "        print(\"... HMM plot complete.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 8. MODULE 7: CONCEPTUAL VISUALIZATIONS FOR SECURITY & PRIVACY\n",
    "# ==============================================================================\n",
    "class SecurityPrivacyVisuals:\n",
    "\n",
    "    def plot_federated_learning(self, ax):\n",
    "\n",
    "        print(\"Plotting Federated Learning concept...\")\n",
    "        ax.set_title('Conceptual Diagram of Federated Learning')\n",
    "        \n",
    "\n",
    "        ax.add_patch(plt.Circle((0.5, 0.8), 0.1, color='red', alpha=0.7))\n",
    "        ax.text(0.5, 0.8, 'Global\\nModel', ha='center', va='center', color='white', weight='bold')\n",
    "        \n",
    "\n",
    "        client_pos = [(0.2, 0.2), (0.5, 0.2), (0.8, 0.2)]\n",
    "        client_labels = ['Player 1\\n(Local Data)', 'Player 2\\n(Local Data)', 'Player 3\\n(Local Data)']\n",
    "        for i, pos in enumerate(client_pos):\n",
    "            ax.add_patch(plt.Rectangle((pos[0]-0.1, pos[1]-0.08), 0.2, 0.16, color='skyblue'))\n",
    "            ax.text(pos[0], pos[1], client_labels[i], ha='center', va='center')\n",
    "\n",
    "            con_down = ConnectionPatch(xyA=(0.5, 0.7), xyB=(pos[0], pos[1]+0.08), coordsA=\"data\", coordsB=\"data\",\n",
    "                                       axesA=ax, axesB=ax, arrowstyle=\"->\", shrinkB=5, color='black', alpha=0.6)\n",
    "            ax.add_artist(con_down)\n",
    "            \n",
    "\n",
    "            con_up = ConnectionPatch(xyA=(pos[0], pos[1]+0.08), xyB=(0.5, 0.7), coordsA=\"data\", coordsB=\"data\",\n",
    "                                     axesA=ax, axesB=ax, arrowstyle=\"->\", shrinkB=5, color='green', linestyle='--')\n",
    "            ax.add_artist(con_up)\n",
    "\n",
    "        ax.text(0.5, 0.5, '1. Download\\nGlobal Model', ha='center', va='center', style='italic', color='black')\n",
    "        ax.text(0.5, 0.4, '2. Train Locally', ha='center', va='center', style='italic', color='blue')\n",
    "        ax.text(0.5, 0.3, '3. Upload Encrypted\\nModel Updates', ha='center', va='center', style='italic', color='green')\n",
    "        \n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.axis('off')\n",
    "        print(\"... Federated Learning plot complete.\")\n",
    "        \n",
    "    def plot_differential_privacy(self, ax):\n",
    "\n",
    "        print(\"Plotting Differential Privacy concept...\")\n",
    "        ax.set_title('Conceptual Diagram of Differential Privacy')\n",
    "\n",
    "\n",
    "        x = np.linspace(-4, 4, 1000)\n",
    "        original_dist = norm.pdf(x, 0, 1)\n",
    "        ax.plot(x, original_dist, color='blue', linewidth=2, label='Original Data Query Result')\n",
    "        \n",
    "\n",
    "        noisy_dist = norm.pdf(x, 0, 1.2) \n",
    "        ax.fill_between(x, original_dist, noisy_dist, color='red', alpha=0.3, label='Added Statistical Noise')\n",
    "        ax.plot(x, noisy_dist, color='red', linestyle='--', linewidth=2, label='Noisy (Private) Result')\n",
    "\n",
    "        ax.text(0, 0.3, 'Query(DB) vs Query(DB\\')', ha='center', va='center', fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "        ax.annotate('Individual contribution\\nis masked by noise', xy=(2, 0.1), xytext=(2.5, 0.2),\n",
    "                    arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=5))\n",
    "\n",
    "        ax.set_xlabel('Query Result Value')\n",
    "        ax.set_ylabel('Probability Density')\n",
    "        ax.legend(loc='upper left')\n",
    "        ax.set_yticks([])\n",
    "        print(\"... Differential Privacy plot complete.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 8. MODULE 8: TABLE GENERATION UTILITY\n",
    "# ==============================================================================\n",
    "class TableGenerator:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.tables = {}\n",
    "\n",
    "    def generate_all_tables(self, analysis_modules):\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"GENERATING DATA TABLES FOR MANUSCRIPT\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "\n",
    "        foundational_analyzer = analysis_modules['foundational']\n",
    "        self.tables['correlation'] = foundational_analyzer.analysis_results['correlation_matrix']\n",
    "        pca_res = foundational_analyzer.analysis_results\n",
    "        self.tables['pca'] = pd.DataFrame({\n",
    "            'Principal Component': ['PC1', 'PC2'],\n",
    "            'Explained Variance': pca_res['pca_explained_variance'],\n",
    "            'Cumulative Variance': np.cumsum(pca_res['pca_explained_variance'])\n",
    "        })\n",
    "\n",
    "\n",
    "        ts_analyzer = analysis_modules['ts']\n",
    "        arima_preds = ts_analyzer.analysis_results.get('arima_predictions', [])\n",
    "        lstm_preds = ts_analyzer.analysis_results.get('lstm_predictions', [])\n",
    "        actual = ts_analyzer.test_data.values\n",
    "\n",
    "        min_len = min(len(arima_preds), len(lstm_preds), len(actual))\n",
    "        if min_len > 0:\n",
    "            self.tables['ts_forecast'] = pd.DataFrame({\n",
    "                'Time': ts_analyzer.test_data.index[:min_len],\n",
    "                'Actual Heart Rate': actual[:min_len],\n",
    "                'ARIMA Forecast': arima_preds[:min_len],\n",
    "                'LSTM Forecast': lstm_preds[:min_len]\n",
    "            }).set_index('Time').head(15)\n",
    "\n",
    "\n",
    "        rl_analyzer = analysis_modules['rl']\n",
    "        if 'rl_rewards' in rl_analyzer.analysis_results:\n",
    "            self.tables['rl_rewards'] = pd.DataFrame({\n",
    "                'Episode': range(1, len(rl_analyzer.analysis_results['rl_rewards']) + 1),\n",
    "                'Total Reward': rl_analyzer.analysis_results['rl_rewards']\n",
    "            }).set_index('Episode').tail(15)\n",
    "        \n",
    "\n",
    "        moo_analyzer = analysis_modules['moo']\n",
    "        if 'pareto_front' in moo_analyzer.analysis_results:\n",
    "            self.tables['moo_pareto'] = pd.DataFrame(\n",
    "                moo_analyzer.analysis_results['pareto_front'],\n",
    "                columns=['Objective 1 (Latency)', 'Objective 2 (Energy)']\n",
    "            ).head(15)\n",
    "\n",
    "\n",
    "        hmm_analyzer = analysis_modules['hmm']\n",
    "        sim_data = analysis_modules['sim_data']\n",
    "        if 'inferred_states' in hmm_analyzer.analysis_results:\n",
    "\n",
    "            hmm_df = pd.DataFrame({\n",
    "                'Observation (HR)': sim_data['heart_rate'].values,\n",
    "                'Ground Truth State': sim_data['player_state'].values,\n",
    "                'Inferred State': hmm_analyzer.analysis_results['inferred_states']\n",
    "            })\n",
    "            self.tables['hmm_inference'] = hmm_df.iloc[1000:1015]\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def print_all_tables(self):\n",
    "\n",
    "        for name, table in self.tables.items():\n",
    "            title = f\" TABLE: {name.replace('_', ' ').upper()} \"\n",
    "            print(\"\\n\" + title.center(80, \"-\"))\n",
    "            print(table.to_string())\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "# ==============================================================================\n",
    "# 9. MODULE 9: MASTER PLOTTING ORCHESTRATOR\n",
    "# ==============================================================================\n",
    "def create_master_plot(analysis_modules, filename=\"iot_sg_analysis_figure.pdf\"):\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CREATING MASTER VISUALIZATION\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 28))\n",
    "    fig.suptitle('Comprehensive Analysis of IoT-Enabled Serious Games Data', fontsize=24, y=0.99)\n",
    "    \n",
    "    gs = gridspec.GridSpec(6, 2, figure=fig, hspace=0.6, wspace=0.3, height_ratios=[1.5, 1, 1, 1, 1, 1])\n",
    "    \n",
    "\n",
    "    ax_data_overview = fig.add_subplot(gs[0, :])\n",
    "    plot_data_overview(ax_data_overview, analysis_modules['sim_data'])\n",
    "    \n",
    "\n",
    "    ax_corr = fig.add_subplot(gs[1, 0])\n",
    "    analysis_modules['foundational'].plot_correlation_heatmap(ax_corr)\n",
    "    \n",
    "    ax_pca = fig.add_subplot(gs[1, 1])\n",
    "    analysis_modules['foundational'].plot_pca(ax_pca)\n",
    "    \n",
    "\n",
    "    ax_ts = fig.add_subplot(gs[2, 0])\n",
    "    analysis_modules['ts'].plot_forecasts(ax_ts)\n",
    "    \n",
    "    ax_network = fig.add_subplot(gs[2, 1])\n",
    "    analysis_modules['foundational'].plot_sensor_network(ax_network)\n",
    "    \n",
    "\n",
    "    ax_rl = fig.add_subplot(gs[3, :])\n",
    "    analysis_modules['rl'].plot_rl_training(ax_rl)\n",
    "    \n",
    "\n",
    "    ax_moo = fig.add_subplot(gs[4, 0])\n",
    "    analysis_modules['moo'].plot_pareto_front(ax_moo)\n",
    "    \n",
    "    ax_hmm = fig.add_subplot(gs[4, 1])\n",
    "    analysis_modules['hmm'].plot_inferred_states(ax_hmm, analysis_modules['sim_data']['player_state'])\n",
    "    \n",
    "\n",
    "    ax_fl = fig.add_subplot(gs[5, 0])\n",
    "    analysis_modules['security'].plot_federated_learning(ax_fl)\n",
    "    \n",
    "    ax_dp = fig.add_subplot(gs[5, 1])\n",
    "    analysis_modules['security'].plot_differential_privacy(ax_dp)\n",
    "\n",
    "\n",
    "    subplot_labels = {\n",
    "        'a': ax_data_overview, 'b': ax_corr, 'c': ax_pca,\n",
    "        'd': ax_ts, 'e': ax_network, 'f': ax_rl,\n",
    "        'g': ax_moo, 'h': ax_hmm, 'i': ax_fl, 'j': ax_dp\n",
    "    }\n",
    "    for label, ax in subplot_labels.items():\n",
    "\n",
    "        ax.text(0.0, 1.05, f'({label})', transform=ax.transAxes, fontsize=16, fontweight='bold', va='bottom', ha='left')\n",
    "\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97]) \n",
    "    try:\n",
    "        fig.savefig(filename, bbox_inches='tight', dpi=300)\n",
    "        print(f\"\\nMaster plot saved successfully to '{filename}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError saving plot: {e}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_data_overview(ax, sim_data):\n",
    "\n",
    "    print(\"Plotting simulated data overview...\")\n",
    "    ax.set_title('Overview of Simulated Multi-Modal IoT Data')\n",
    "    ax2 = ax.twinx()\n",
    "\n",
    "\n",
    "    p1, = ax.plot(sim_data.index.total_seconds(), sim_data['ecg'], color='lightblue', label='ECG Signal')\n",
    "    p2, = ax2.plot(sim_data.index.total_seconds(), sim_data['heart_rate'], color='red', linestyle='--', label='Heart Rate (BPM)')\n",
    "\n",
    "    p3, = ax2.plot(sim_data.index.total_seconds(), sim_data['game_score'] / 10, color='green', linestyle=':', label='Game Score / 10')\n",
    "    \n",
    "\n",
    "    state_colors = {'CALM': 'gray', 'FOCUSED': 'green', 'FRUSTRATED': 'red', 'FATIGUED': 'purple'}\n",
    "\n",
    "    legend_handles = []\n",
    "    for state, color in state_colors.items():\n",
    "        ax.fill_between(sim_data.index.total_seconds(), -2, 2, where=(sim_data['player_state'] == state),\n",
    "                        color=color, alpha=0.2)\n",
    "        legend_handles.append(plt.Rectangle((0,0),1,1, color=color, alpha=0.3, label=f'State: {state}'))\n",
    "\n",
    "\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('ECG Signal Amplitude (mV)')\n",
    "    ax2.set_ylabel('Heart Rate / Score')\n",
    "    ax.set_ylim(-2, 2)\n",
    "    ax2.set_ylim(40, 120)\n",
    "    \n",
    "\n",
    "    lines = [p1, p2, p3] + legend_handles\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax.legend(lines, labels, loc='upper left', ncol=3)\n",
    "    print(\"... Data overview plot complete.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 11. MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "def main():\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"=\"*80)\n",
    "    print(\" STARTING COMPREHENSIVE ANALYSIS FOR IOT-ENABLED SERIOUS GAMES \")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "    simulator = IoTSeriousGameSimulator(n_samples=N_SAMPLES, sampling_rate=SAMPLING_RATE)\n",
    "    simulated_data = simulator.run_simulation()\n",
    "\n",
    "\n",
    "    print(\"\\n--- Initializing Analysis Modules ---\")\n",
    "    foundational_analyzer = FoundationalAnalysis(simulated_data).calculate_correlation_matrix().perform_pca().create_sensor_network_graph()\n",
    "    ts_analyzer = TimeSeriesAnalysis(simulated_data).train_arima_model().train_lstm_model()\n",
    "    rl_analyzer = RLAnalysis(episodes=150).run_training()\n",
    "    moo_analyzer = MOOAnalysis(n_generations=100).run_genetic_algorithm()\n",
    "    hmm_analyzer = HMMAnalysis(simulated_data).run_viterbi_algorithm()\n",
    "    security_visualizer = SecurityPrivacyVisuals()\n",
    "    \n",
    "    analysis_modules = {\n",
    "        'sim_data': simulated_data,\n",
    "        'foundational': foundational_analyzer,\n",
    "        'ts': ts_analyzer,\n",
    "        'rl': rl_analyzer,\n",
    "        'moo': moo_analyzer,\n",
    "        'hmm': hmm_analyzer,\n",
    "        'security': security_visualizer\n",
    "    }\n",
    "\n",
    "\n",
    "    table_gen = TableGenerator()\n",
    "    table_gen.generate_all_tables(analysis_modules)\n",
    "    table_gen.print_all_tables()\n",
    "    \n",
    "\n",
    "    create_master_plot(analysis_modules)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\" ENTIRE ANALYSIS PIPELINE COMPLETED IN {end_time - start_time:.2f} SECONDS \")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dfddef-cac5-4397-92a8-bf41a7da1a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "\n",
    "from hmmlearn import hmm\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "def setup_global_styling():\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.style.use('seaborn-v0_8-paper')\n",
    "    plt.rcParams.update({\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times New Roman\"],\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"axes.titlesize\": 12,\n",
    "        \"xtick.labelsize\": 8,\n",
    "        \"ytick.labelsize\": 8,\n",
    "        \"legend.fontsize\": 8,\n",
    "        \"figure.titlesize\": 14,\n",
    "        \"lines.linewidth\": 1.5,\n",
    "        \"lines.markersize\": 4,\n",
    "    })\n",
    "\n",
    "\n",
    "def generate_status_data(num_records=1000):\n",
    "\n",
    "    data = {\n",
    "        'timestamp': pd.to_datetime(np.arange(num_records), unit='m', origin=pd.Timestamp('2025-01-01')),\n",
    "        'sensor_id': np.random.randint(1, 21, num_records),\n",
    "        'game_id': np.random.choice(['GameA', 'GameB', 'GameC'], num_records),\n",
    "        'player_id': np.random.randint(100, 111, num_records),\n",
    "        'sensor_type': np.random.choice(['Temperature', 'Humidity', 'Gyroscope', 'Accelerometer'], num_records),\n",
    "        'status': np.random.choice(['active', 'inactive', 'error'], num_records, p=[0.85, 0.1, 0.05]),\n",
    "        'battery_level': np.random.uniform(0.1, 1.0, num_records)\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def generate_location_data(num_records=5000):\n",
    "\n",
    "    timestamps = pd.to_datetime(np.arange(num_records), unit='s', origin=pd.Timestamp('2025-01-01 12:00:00'))\n",
    "    player_ids = np.repeat(np.arange(1, 6), num_records // 5)\n",
    "    \n",
    "    x = 0.1 * np.sin(np.linspace(0, 50, num_records)) + np.random.randn(num_records) * 0.05\n",
    "    y = 0.1 * np.cos(np.linspace(0, 50, num_records)) + np.random.randn(num_records) * 0.05\n",
    "    z = np.linspace(0, 2, num_records) + np.random.randn(num_records) * 0.02\n",
    "    \n",
    "    data = {\n",
    "        'timestamp': timestamps,\n",
    "        'player_id': player_ids,\n",
    "        'accel_x': x,\n",
    "        'accel_y': y,\n",
    "        'accel_z': z,\n",
    "        'gyro_x': np.gradient(x),\n",
    "        'gyro_y': np.gradient(y),\n",
    "        'gyro_z': np.gradient(z),\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def generate_automation_data(num_records=2000):\n",
    "\n",
    "    data = {\n",
    "        'timestamp': pd.to_datetime(np.arange(num_records), unit='ms', origin=pd.Timestamp('2025-01-01 12:00:00')),\n",
    "        'player_id': np.random.randint(100, 111, num_records),\n",
    "        'input_type': np.random.choice(['button', 'touch', 'voice'], num_records, p=[0.6, 0.3, 0.1]),\n",
    "        'action_id': np.random.choice(['jump', 'crouch', 'fire', 'move_forward', 'use_item'], num_records),\n",
    "        'pressure': np.random.uniform(0, 1, num_records),\n",
    "        'duration_ms': np.random.randint(50, 500, num_records)\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def generate_actionable_data(num_records=1500):\n",
    "\n",
    "    data = {\n",
    "        'timestamp': pd.to_datetime(np.arange(num_records), unit='s', origin=pd.Timestamp('2025-01-01 12:00:00')),\n",
    "        'player_id': np.random.randint(100, 111, num_records),\n",
    "        'action_type': np.random.choice(['power_up', 'game_over', 'level_complete', 'task_failed'], num_records),\n",
    "        'score_change': np.random.randint(-100, 250, num_records),\n",
    "        'action_value': np.random.rand(num_records) * 100,\n",
    "        'action_status': np.random.choice(['success', 'pending', 'fail'], num_records, p=[0.7, 0.1, 0.2])\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def generate_physiological_data(num_records=10000):\n",
    "\n",
    "    time_s = np.arange(num_records)\n",
    "    base_hr = 75\n",
    "    hr_drift = base_hr + 5 * np.sin(time_s / 500) + np.random.normal(0, 2, num_records)\n",
    "    hr_spikes = np.random.choice([0, 1], size=num_records, p=[0.99, 0.01]) * np.random.randint(20, 40, num_records)\n",
    "    hr = hr_drift + hr_spikes\n",
    "\n",
    "    base_temp = 36.8\n",
    "    temperature = base_temp + 0.5 * np.sin(time_s / 1000) + np.random.normal(0, 0.1, num_records)\n",
    "    \n",
    "    data = {\n",
    "        'timestamp': pd.to_datetime(time_s, unit='s', origin=pd.Timestamp('2025-01-01 12:00:00')),\n",
    "        'player_id': 101,\n",
    "        'heart_rate': hr,\n",
    "        'temperature_c': temperature,\n",
    "        'gsr': 10 * np.sin(time_s / 200) + np.random.normal(0, 1, num_records) + 50\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "def print_section_header(title):\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"| {title.center(76)} |\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "def perform_descriptive_analysis(df, title):\n",
    "\n",
    "    print_section_header(f\"Descriptive Analysis: {title}\")\n",
    "    print(\"--- First 5 Rows ---\")\n",
    "    print(df.head())\n",
    "    print(\"\\n\" + \"--- Data Info ---\")\n",
    "    df.info()\n",
    "    print(\"\\n\" + \"--- Descriptive Statistics ---\")\n",
    "    print(df.describe().to_string())\n",
    "    if df.select_dtypes(include=[np.number]).shape[1] > 1:\n",
    "        print(\"\\n\" + \"--- Correlation Matrix ---\")\n",
    "        print(df.corr(numeric_only=True).to_string())\n",
    "    print(\"\\n\")\n",
    "\n",
    "def plot_statistical_overview(dfs, fig):\n",
    "\n",
    "    subfigs = fig.subfigures(2, 1, hspace=0.07)\n",
    "\n",
    "\n",
    "    ax_top = subfigs[0].subplots(1, 3)\n",
    "    subfigs[0].suptitle('Sensor Network and Player Input Analysis', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    status_df = dfs['status']\n",
    "    sns.countplot(data=status_df, y='status', ax=ax_top[0], palette='viridis', order=status_df['status'].value_counts().index)\n",
    "    ax_top[0].set_title('Sensor Status Distribution')\n",
    "    ax_top[0].set_xlabel('Count')\n",
    "    ax_top[0].set_ylabel('Status')\n",
    "    ax_top[0].text(-0.1, 1.05, '(a)', transform=ax_top[0].transAxes, size=12, weight='bold')\n",
    "\n",
    "    status_df['sensor_type'].value_counts().plot.pie(autopct='%1.1f%%', ax=ax_top[1], startangle=90, colors=sns.color_palette('pastel'))\n",
    "    ax_top[1].set_title('Sensor Type Proportions')\n",
    "    ax_top[1].set_ylabel('')\n",
    "    ax_top[1].text(-0.1, 1.05, '(b)', transform=ax_top[1].transAxes, size=12, weight='bold')\n",
    "\n",
    "    automation_df = dfs['automation']\n",
    "    sns.countplot(data=automation_df, x='action_id', ax=ax_top[2], palette='magma')\n",
    "    ax_top[2].set_title('Player Action Frequencies')\n",
    "    ax_top[2].tick_params(axis='x', rotation=45)\n",
    "    ax_top[2].set_xlabel('Action ID')\n",
    "    ax_top[2].set_ylabel('Frequency')\n",
    "    ax_top[2].text(-0.1, 1.05, '(c)', transform=ax_top[2].transAxes, size=12, weight='bold')\n",
    "\n",
    "\n",
    "    ax_bottom = subfigs[1].subplots(1, 3)\n",
    "    subfigs[1].suptitle('Player Movement and Game Outcome Analysis', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    location_df = dfs['location']\n",
    "    sns.kdeplot(data=location_df, x='accel_x', y='accel_y', fill=True, cmap='mako', ax=ax_bottom[0])\n",
    "    ax_bottom[0].set_title('Player Movement Density (Accel)')\n",
    "    ax_bottom[0].set_xlabel('Acceleration X')\n",
    "    ax_bottom[0].set_ylabel('Acceleration Y')\n",
    "    ax_bottom[0].text(-0.1, 1.05, '(d)', transform=ax_bottom[0].transAxes, size=12, weight='bold')\n",
    "\n",
    "    actionable_df = dfs['actionable']\n",
    "    sns.violinplot(data=actionable_df, x='action_type', y='score_change', ax=ax_bottom[1], palette='rocket')\n",
    "    ax_bottom[1].set_title('Score Change by Action Type')\n",
    "    ax_bottom[1].tick_params(axis='x', rotation=45)\n",
    "    ax_bottom[1].set_xlabel('Action Type')\n",
    "    ax_bottom[1].set_ylabel('Score Change')\n",
    "    ax_bottom[1].text(-0.1, 1.05, '(e)', transform=ax_bottom[1].transAxes, size=12, weight='bold')\n",
    "\n",
    "    corr = location_df[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']].corr()\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', ax=ax_bottom[2], annot_kws={\"size\": 7})\n",
    "    ax_bottom[2].set_title('Sensor Correlation Heatmap')\n",
    "    ax_bottom[2].tick_params(axis='x', rotation=45)\n",
    "    ax_bottom[2].text(-0.1, 1.05, '(f)', transform=ax_bottom[2].transAxes, size=12, weight='bold')\n",
    "\n",
    "def plot_pca_analysis(df, fig):\n",
    "\n",
    "    fig.suptitle('Principal Component Analysis of Player Movement', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    features = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "    x = df[features].values\n",
    "    x = StandardScaler().fit_transform(x)\n",
    "    \n",
    "    pca = PCA(n_components=3)\n",
    "    principalComponents = pca.fit_transform(x)\n",
    "    \n",
    "\n",
    "    ax1 = fig.add_subplot(2, 2, 1)\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    ax1.bar(range(1, 4), explained_variance * 100, alpha=0.8, align='center', label='Individual explained variance')\n",
    "    ax1.step(range(1, 4), np.cumsum(explained_variance) * 100, where='mid', label='Cumulative explained variance', color='red')\n",
    "    ax1.set_ylabel('Explained Variance (%)')\n",
    "    ax1.set_xlabel('Principal Components')\n",
    "    ax1.set_title('Explained Variance by Component')\n",
    "    ax1.legend(loc='best')\n",
    "    ax1.text(-0.1, 1.05, '(a)', transform=ax1.transAxes, size=12, weight='bold')\n",
    "\n",
    "\n",
    "    ax2 = fig.add_subplot(2, 2, 2)\n",
    "    ax2.scatter(principalComponents[:, 0], principalComponents[:, 1], c=df['player_id'], cmap='viridis', alpha=0.5, s=10)\n",
    "    ax2.set_xlabel('Principal Component 1')\n",
    "    ax2.set_ylabel('Principal Component 2')\n",
    "    ax2.set_title('2D PCA of Player Movement')\n",
    "    ax2.text(-0.1, 1.05, '(b)', transform=ax2.transAxes, size=12, weight='bold')\n",
    "    \n",
    "\n",
    "    ax3 = fig.add_subplot(2, 1, 2, projection='3d')\n",
    "    scatter = ax3.scatter(principalComponents[:, 0], principalComponents[:, 1], principalComponents[:, 2], c=df['player_id'], cmap='plasma', s=5, alpha=0.6)\n",
    "    ax3.set_title('3D PCA Visualization')\n",
    "    ax3.set_xlabel('PC 1')\n",
    "    ax3.set_ylabel('PC 2')\n",
    "    ax3.set_zlabel('PC 3')\n",
    "    legend1 = ax3.legend(*scatter.legend_elements(), title=\"Players\")\n",
    "    ax3.add_artist(legend1)\n",
    "\n",
    "    ax3.text2D(-0.1, 1.0, '(c)', transform=ax3.transAxes, size=12, weight='bold')\n",
    "\n",
    "\n",
    "\n",
    "def plot_time_series_overview(df, fig):\n",
    "\n",
    "    fig.suptitle('Physiological Time Series Data Overview (Player 101)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    ax1 = fig.add_subplot(3, 1, 1)\n",
    "    ax1.plot(df['timestamp'], df['heart_rate'], label='Heart Rate (BPM)', color='red', alpha=0.8)\n",
    "    ax1.set_title('Heart Rate Over Time')\n",
    "    ax1.set_ylabel('BPM')\n",
    "    ax1.legend()\n",
    "    ax1.text(-0.1, 1.05, '(a)', transform=ax1.transAxes, size=12, weight='bold')\n",
    "\n",
    "    ax2 = fig.add_subplot(3, 1, 2)\n",
    "    ax2.plot(df['timestamp'], df['temperature_c'], label='Body Temperature (C)', color='blue', alpha=0.8)\n",
    "    ax2.set_title('Body Temperature Over Time')\n",
    "    ax2.set_ylabel('C')\n",
    "    ax2.legend()\n",
    "    ax2.text(-0.1, 1.05, '(b)', transform=ax2.transAxes, size=12, weight='bold')\n",
    "\n",
    "    ax3 = fig.add_subplot(3, 1, 3)\n",
    "    ax3.plot(df['timestamp'], df['gsr'], label='Galvanic Skin Response', color='green', alpha=0.8)\n",
    "    ax3.set_title('Galvanic Skin Response (GSR) Over Time')\n",
    "    ax3.set_ylabel('Microsiemens')\n",
    "    ax3.set_xlabel('Timestamp')\n",
    "    ax3.legend()\n",
    "    ax3.text(-0.1, 1.05, '(c)', transform=ax3.transAxes, size=12, weight='bold')\n",
    "    \n",
    "def arima_analysis_and_plot(series, p, d, q, title, ax):\n",
    "\n",
    "\n",
    "    result = adfuller(series.dropna())\n",
    "    is_stationary = result[1] <= 0.05\n",
    "\n",
    "    model = ARIMA(series, order=(p, d, q))\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    ax.plot(series.index, series, label='Original Data', color='black')\n",
    "    ax.plot(model_fit.predict(start=series.index[0], end=series.index[-1]), color='red', label='ARIMA Fit')\n",
    "    \n",
    "    forecast = model_fit.get_forecast(steps=50)\n",
    "    forecast_index = pd.date_range(start=series.index[-1], periods=51, freq='S')[1:]\n",
    "    forecast_series = forecast.predicted_mean\n",
    "    conf_int = forecast.conf_int()\n",
    "\n",
    "    ax.plot(forecast_index, forecast_series, color='blue', label='Forecast')\n",
    "    ax.fill_between(forecast_index, conf_int.iloc[:, 0], conf_int.iloc[:, 1], color='pink', alpha=0.5, label='95% Confidence Interval')\n",
    "    \n",
    "    ax.set_title(f'{title} - ARIMA({p},{d},{q}) (Stationary: {is_stationary})')\n",
    "    ax.legend()\n",
    "    \n",
    "def plot_arima_models(df, fig):\n",
    "\n",
    "    fig.suptitle('Time Series Forecasting with ARIMA Models', fontsize=14, fontweight='bold')\n",
    "    df_resampled = df.set_index('timestamp').resample('10S').mean()\n",
    "\n",
    "    ax1 = fig.add_subplot(2, 1, 1)\n",
    "    arima_analysis_and_plot(df_resampled['heart_rate'], 5, 1, 0, 'Heart Rate Forecast', ax1)\n",
    "    ax1.text(-0.1, 1.05, '(a)', transform=ax1.transAxes, size=12, weight='bold')\n",
    "\n",
    "    ax2 = fig.add_subplot(2, 1, 2)\n",
    "    arima_analysis_and_plot(df_resampled['gsr'], 3, 1, 1, 'GSR Forecast', ax2)\n",
    "    ax2.text(-0.1, 1.05, '(b)', transform=ax2.transAxes, size=12, weight='bold')\n",
    "\n",
    "def create_lstm_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back - 1):\n",
    "        a = dataset[i:(i + look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def build_and_train_lstm(series):\n",
    "\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dataset = scaler.fit_transform(series.values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "    train_size = int(len(dataset) * 0.8)\n",
    "    train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
    "\n",
    "    look_back = 30\n",
    "    trainX, trainY = create_lstm_dataset(train, look_back)\n",
    "    testX, testY = create_lstm_dataset(test, look_back)\n",
    "\n",
    "\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "    testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(look_back, 1), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "\n",
    "    history = model.fit(trainX[:5000], trainY[:5000], epochs=5, batch_size=64, verbose=0, validation_split=0.1)\n",
    "\n",
    "\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "\n",
    "\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY_inv = scaler.inverse_transform([trainY])\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY_inv = scaler.inverse_transform([testY])\n",
    "    \n",
    "    return trainPredict, testPredict, trainY_inv, testY_inv, history, look_back, scaler\n",
    "\n",
    "def plot_lstm_results(series, trainPredict, testPredict, history, look_back, fig):\n",
    "\n",
    "    fig.suptitle('Deep Learning for Physiological Forecasting (LSTM)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    ax1 = fig.add_subplot(2, 1, 1)\n",
    "    ax1.plot(history.history['loss'], label='Training Loss')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax1.set_title('LSTM Model Training History')\n",
    "    ax1.set_ylabel('Loss (MSE)')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend()\n",
    "    ax1.text(-0.1, 1.05, '(a)', transform=ax1.transAxes, size=12, weight='bold')\n",
    "\n",
    "    ax2 = fig.add_subplot(2, 1, 2)\n",
    "    \n",
    "\n",
    "    trainPredictPlot = np.empty_like(series.values.reshape(-1, 1))\n",
    "    trainPredictPlot[:, :] = np.nan\n",
    "    trainPredictPlot[look_back:len(trainPredict) + look_back, :] = trainPredict\n",
    "\n",
    "\n",
    "    testPredictPlot = np.empty_like(series.values.reshape(-1, 1))\n",
    "    testPredictPlot[:, :] = np.nan\n",
    "    test_start_index = len(trainPredict) + (look_back * 2) + 1\n",
    "    testPredictPlot[test_start_index:len(series) - 1, :] = testPredict\n",
    "\n",
    "\n",
    "    ax2.plot(series.index, series.values, label='Original Data', color='black', alpha=0.5)\n",
    "    ax2.plot(series.index, trainPredictPlot, label='Training Prediction', color='orange')\n",
    "    ax2.plot(series.index, testPredictPlot, label='Testing Prediction', color='red')\n",
    "    ax2.set_title('Heart Rate Prediction vs Actual')\n",
    "    ax2.set_ylabel('Heart Rate (BPM)')\n",
    "    ax2.set_xlabel('Timestamp')\n",
    "    ax2.legend()\n",
    "    ax2.text(-0.1, 1.05, '(b)', transform=ax2.transAxes, size=12, weight='bold')\n",
    "\n",
    "\n",
    "\n",
    "class SimpleGameEnv:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.state_space = 10  \n",
    "        self.action_space = 3 \n",
    "        self.state = np.random.randint(0, self.state_space)\n",
    "        self.difficulty = 5\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.random.randint(0, self.state_space)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        if action == 0: self.difficulty = max(0, self.difficulty - 1)\n",
    "        elif action == 2: self.difficulty = min(9, self.difficulty + 1)\n",
    "        \n",
    "\n",
    "        reward = 1.0 - abs(self.state - self.difficulty) / self.state_space\n",
    "        \n",
    "\n",
    "        if self.difficulty > self.state: \n",
    "            self.state = max(0, self.state - np.random.choice([0, 1], p=[0.7, 0.3]))\n",
    "        elif self.difficulty < self.state: \n",
    "             self.state = min(9, self.state + np.random.choice([0, 1], p=[0.6, 0.4]))\n",
    "        else: \n",
    "             self.state = min(9, self.state + np.random.choice([0, 1], p=[0.4, 0.6]))\n",
    "        \n",
    "        done = False \n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "def train_q_learning_agent(env, episodes=1000):\n",
    "\n",
    "    q_table = np.zeros([env.state_space, env.action_space])\n",
    "    \n",
    "    alpha = 0.1  \n",
    "    gamma = 0.6  \n",
    "    epsilon = 0.1 \n",
    "\n",
    "    rewards = []\n",
    "    for i in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        \n",
    "        for _ in range(100): \n",
    "            if np.random.uniform(0, 1) < epsilon:\n",
    "                action = np.random.randint(0, env.action_space) \n",
    "            else:\n",
    "                action = np.argmax(q_table[state]) \n",
    "            \n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            old_value = q_table[state, action]\n",
    "            next_max = np.max(q_table[next_state])\n",
    "            \n",
    "            new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "            q_table[state, action] = new_value\n",
    "            \n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "        rewards.append(total_reward)\n",
    "    \n",
    "    return q_table, rewards\n",
    "\n",
    "def plot_rl_results(q_table, rewards, fig):\n",
    "\n",
    "    fig.suptitle('Reinforcement Learning for Dynamic Difficulty Adjustment', fontsize=14, fontweight='bold')\n",
    "\n",
    "    ax1 = fig.add_subplot(2, 1, 1)\n",
    "    ax1.plot(pd.Series(rewards).rolling(50).mean())\n",
    "    ax1.set_title('Q-Learning Agent Performance Over Time (Rolling Mean Reward)')\n",
    "    ax1.set_xlabel('Episodes')\n",
    "    ax1.set_ylabel('Average Reward')\n",
    "    ax1.text(-0.1, 1.05, '(a)', transform=ax1.transAxes, size=12, weight='bold')\n",
    "\n",
    "    ax2 = fig.add_subplot(2, 2, 3)\n",
    "    sns.heatmap(q_table, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", ax=ax2, cbar=False)\n",
    "    ax2.set_title('Learned Q-Table')\n",
    "    ax2.set_xlabel('Action (0: Dec, 1: Keep, 2: Inc)')\n",
    "    ax2.set_ylabel('Player Skill State')\n",
    "    ax2.text(-0.1, 1.05, '(b)', transform=ax2.transAxes, size=12, weight='bold')\n",
    "\n",
    "    ax3 = fig.add_subplot(2, 2, 4)\n",
    "    policy = np.argmax(q_table, axis=1)\n",
    "    policy_map = policy.reshape(1, -1)\n",
    "    sns.heatmap(policy_map, annot=True, fmt=\".0f\", cmap=\"coolwarm\", cbar=False, ax=ax3, yticklabels=False)\n",
    "    ax3.set_title('Optimal Policy (Action to take at each skill state)')\n",
    "    ax3.set_xlabel('Player Skill State')\n",
    "    ax3.set_xticklabels(range(10))\n",
    "    ax3.text(-0.1, 1.05, '(c)', transform=ax3.transAxes, size=12, weight='bold')\n",
    "\n",
    "\n",
    "\n",
    "def simulate_and_plot_hmm(fig):\n",
    "\n",
    "    fig.suptitle('Stochastic Modeling of Player State with HMM', fontsize=14, fontweight='bold')\n",
    "    \n",
    "\n",
    "    model = hmm.GaussianHMM(n_components=3, covariance_type=\"diag\", n_iter=100)\n",
    "    model.startprob_ = np.array([0.6, 0.3, 0.1])\n",
    "    model.transmat_ = np.array([[0.7, 0.2, 0.1],\n",
    "                                [0.1, 0.8, 0.1],\n",
    "                                [0.2, 0.3, 0.5]])\n",
    "\n",
    "    model.means_ = np.array([[50.0], [150.0], [-50.0]])\n",
    "    model.covars_ = np.array([[20.0], [30.0], [40.0]])\n",
    "\n",
    "\n",
    "    X, Z = model.sample(n_samples=300)\n",
    "\n",
    "\n",
    "    predicted_states = model.predict(X)\n",
    "\n",
    "\n",
    "    ax1 = fig.add_subplot(2, 1, 1)\n",
    "    ax1.plot(X, label='Observed Score Change', color='black', alpha=0.7, marker='o', linestyle='--')\n",
    "    ax1.set_title('Observed Player Data (Game Score Changes)')\n",
    "    ax1.set_xlabel('Time Step')\n",
    "    ax1.set_ylabel('Score Change')\n",
    "    ax1.legend()\n",
    "    ax1.text(-0.1, 1.05, '(a)', transform=ax1.transAxes, size=12, weight='bold')\n",
    "\n",
    "    ax2 = fig.add_subplot(2, 1, 2)\n",
    "    ax2.plot(Z, label='True Hidden State', linestyle='--', color='gray')\n",
    "    ax2.plot(predicted_states, label='HMM Predicted State', color='red')\n",
    "    ax2.set_yticks([0, 1, 2])\n",
    "    ax2.set_yticklabels(['Bored', 'Engaged', 'Frustrated'])\n",
    "    ax2.set_title('Inferred Player Engagement State')\n",
    "    ax2.set_xlabel('Time Step')\n",
    "    ax2.set_ylabel('Inferred State')\n",
    "    ax2.legend()\n",
    "    ax2.text(-0.1, 1.05, '(b)', transform=ax2.transAxes, size=12, weight='bold')\n",
    "\n",
    "def plot_multi_objective_optimization(fig):\n",
    "\n",
    "    fig.suptitle('Multi-Objective Optimization for Resource Allocation', fontsize=14, fontweight='bold')\n",
    "    \n",
    "\n",
    "    np.random.seed(42)\n",
    "    latency = np.linspace(10, 100, 50)\n",
    "    energy = 1000 / latency + np.random.normal(0, 5, 50)\n",
    "    energy = np.maximum(energy, 10)\n",
    "    \n",
    "\n",
    "    pareto_front = []\n",
    "    sorted_points = sorted(zip(latency, energy))\n",
    "    min_energy = float('inf')\n",
    "    for l, e in sorted_points:\n",
    "        if e < min_energy:\n",
    "            pareto_front.append((l, e))\n",
    "            min_energy = e\n",
    "    pareto_latency, pareto_energy = zip(*pareto_front)\n",
    "\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.scatter(latency, energy, label='All Possible Solutions', alpha=0.5, color='gray')\n",
    "    ax.plot(pareto_latency, pareto_energy, 'r-o', label='Pareto Optimal Front')\n",
    "    ax.set_title('Trade-off between Latency and Energy Consumption')\n",
    "    ax.set_xlabel('Latency (ms)')\n",
    "    ax.set_ylabel('Energy Consumption (Joules)')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    ax.text(-0.1, 1.05, '(a)', transform=ax.transAxes, size=12, weight='bold')\n",
    "\n",
    "def plot_security_privacy_concepts(fig):\n",
    "\n",
    "    fig.suptitle('Illustrations of Privacy-Preserving and Security Concepts', fontsize=14, fontweight='bold')\n",
    "    \n",
    "\n",
    "    ax1 = fig.add_subplot(2, 2, 1)\n",
    "    original_data = np.random.normal(loc=50, scale=10, size=1000)\n",
    "    sns.kdeplot(original_data, ax=ax1, label='Original Data', color='blue', fill=True)\n",
    "\n",
    "    epsilon_1 = 1.0\n",
    "    private_data_1 = original_data + np.random.laplace(0, 10/epsilon_1, 1000)\n",
    "    sns.kdeplot(private_data_1, ax=ax1, label=f'Private (={epsilon_1})', color='orange', linestyle='--')\n",
    "    epsilon_2 = 0.1\n",
    "    private_data_2 = original_data + np.random.laplace(0, 10/epsilon_2, 1000)\n",
    "    sns.kdeplot(private_data_2, ax=ax1, label=f'Private (={epsilon_2})', color='red', linestyle=':')\n",
    "    ax1.set_title('Differential Privacy: Adding Noise')\n",
    "    ax1.set_xlabel('Value')\n",
    "    ax1.set_ylabel('Density')\n",
    "    ax1.legend()\n",
    "    ax1.text(-0.1, 1.05, '(a)', transform=ax1.transAxes, size=12, weight='bold')\n",
    "\n",
    "ng\n",
    "    ax2 = fig.add_subplot(2, 2, 2)\n",
    "    rounds = np.arange(1, 21)\n",
    "    centralized_acc = np.full_like(rounds, 0.95, dtype=float)\n",
    "    federated_acc = 0.95 - 2 * np.exp(-0.5 * rounds) + np.random.normal(0, 0.01, 20)\n",
    "    ax2.plot(rounds, centralized_acc, 'r--', label='Centralized Training (Ideal)')\n",
    "    ax2.plot(rounds, federated_acc, 'b-o', label='Federated Learning')\n",
    "    ax2.set_title('Federated Learning Performance')\n",
    "    ax2.set_xlabel('Communication Rounds')\n",
    "    ax2.set_ylabel('Model Accuracy')\n",
    "    ax2.set_ylim(0.7, 1.0)\n",
    "    ax2.legend()\n",
    "    ax2.text(-0.1, 1.05, '(b)', transform=ax2.transAxes, size=12, weight='bold')\n",
    "\n",
    "\n",
    "    ax3 = fig.add_subplot(2, 2, 3)\n",
    "    x = ['PoW (Bitcoin-like)', 'PoS (Ethereum-like)', 'DPoS (EOS-like)']\n",
    "    y = [7, 20, 4000]\n",
    "    bars = ax3.bar(x, y, color=['#f7931a', '#627eea', '#2c3e50'])\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.set_title('Blockchain Consensus Throughput')\n",
    "    ax3.set_ylabel('Transactions per Second (Log Scale)')\n",
    "    ax3.bar_label(bars)\n",
    "    ax3.text(-0.1, 1.05, '(c)', transform=ax3.transAxes, size=12, weight='bold')\n",
    "    \n",
    "\n",
    "    ax4 = fig.add_subplot(2, 2, 4)\n",
    "    ops = ['Addition', 'Multiplication', 'Bootstrap']\n",
    "    times = [0.01, 0.5, 5.0]\n",
    "    bars = ax4.bar(ops, times, color=['green', 'orange', 'red'])\n",
    "    ax4.set_yscale('log')\n",
    "    ax4.set_title('Homomorphic Encryption Overhead (Simulated)')\n",
    "    ax4.set_ylabel('Computation Time (s, Log Scale)')\n",
    "    ax4.bar_label(bars)\n",
    "    ax4.text(-0.1, 1.05, '(d)', transform=ax4.transAxes, size=12, weight='bold')\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"--- Starting Comprehensive Analysis for IoT-Enabled Serious Games ---\")\n",
    "    \n",
    "\n",
    "    setup_global_styling()\n",
    "    output_pdf_path = \"manuscript_plots.pdf\"\n",
    "    if os.path.exists(output_pdf_path):\n",
    "        os.remove(output_pdf_path)\n",
    "\n",
    "\n",
    "    print(\"\\n[1/7] Generating synthetic datasets...\")\n",
    "    status_df = generate_status_data()\n",
    "    location_df = generate_location_data()\n",
    "    automation_df = generate_automation_data()\n",
    "    actionable_df = generate_actionable_data()\n",
    "    physio_df = generate_physiological_data()\n",
    "    all_dfs = {\n",
    "        'status': status_df, 'location': location_df,\n",
    "        'automation': automation_df, 'actionable': actionable_df,\n",
    "        'physiological': physio_df\n",
    "    }\n",
    "    print(\"...Datasets generated successfully.\")\n",
    "\n",
    "\n",
    "    print(\"\\n[2/7] Performing descriptive analysis and printing tables...\")\n",
    "    perform_descriptive_analysis(status_df, \"Sensor Status Data\")\n",
    "    perform_descriptive_analysis(location_df, \"Player Location/Movement Data\")\n",
    "    perform_descriptive_analysis(automation_df, \"Player Automation/Input Data\")\n",
    "    perform_descriptive_analysis(actionable_df, \"Game Actionable Data\")\n",
    "    perform_descriptive_analysis(physio_df, \"Player Physiological Data\")\n",
    "    \n",
    "    with PdfPages(output_pdf_path) as pdf:\n",
    "\n",
    "        print(\"\\n[3/7] Generating statistical overview plots...\")\n",
    "        fig1 = plt.figure(figsize=(11, 8), constrained_layout=True)\n",
    "        plot_statistical_overview(all_dfs, fig1)\n",
    "        pdf.savefig(fig1)\n",
    "        plt.close(fig1)\n",
    "        print(\"...Page 1/6 (Statistical Overview) saved to PDF.\")\n",
    "\n",
    "\n",
    "        print(\"\\n[4/7] Generating PCA plots...\")\n",
    "        fig2 = plt.figure(figsize=(11, 8), constrained_layout=True)\n",
    "        plot_pca_analysis(location_df.dropna(), fig2)\n",
    "        pdf.savefig(fig2)\n",
    "        plt.close(fig2)\n",
    "        print(\"...Page 2/6 (PCA Analysis) saved to PDF.\")\n",
    "        \n",
    "\n",
    "        print(\"\\n[5/7] Generating Time Series plots (ARIMA & LSTM)...\")\n",
    "\n",
    "        fig3 = plt.figure(figsize=(11, 8), constrained_layout=True)\n",
    "        plot_time_series_overview(physio_df, fig3)\n",
    "        pdf.savefig(fig3)\n",
    "        plt.close(fig3)\n",
    "\n",
    "        fig4 = plt.figure(figsize=(11, 8), constrained_layout=True)\n",
    "        plot_arima_models(physio_df, fig4)\n",
    "        pdf.savefig(fig4)\n",
    "        plt.close(fig4)\n",
    "\n",
    "        hr_series = physio_df.set_index('timestamp')['heart_rate'].resample('10S').mean().interpolate()\n",
    "        trainPredict, testPredict, _, _, history, look_back, _ = build_and_train_lstm(hr_series)\n",
    "        fig5 = plt.figure(figsize=(11, 8), constrained_layout=True)\n",
    "        plot_lstm_results(hr_series, trainPredict, testPredict, history, look_back, fig5)\n",
    "        pdf.savefig(fig5)\n",
    "        plt.close(fig5)\n",
    "        print(\"...Pages 3-5/6 (Time Series) saved to PDF.\")\n",
    "\n",
    "\n",
    "        print(\"\\n[6/7] Generating RL, HMM, and other advanced model plots...\")\n",
    "\n",
    "        env = SimpleGameEnv()\n",
    "        q_table, rewards = train_q_learning_agent(env)\n",
    "        fig6 = plt.figure(figsize=(11, 8), constrained_layout=True)\n",
    "        plot_rl_results(q_table, rewards, fig6)\n",
    "        pdf.savefig(fig6)\n",
    "        plt.close(fig6)\n",
    "\n",
    "        fig7 = plt.figure(figsize=(11, 8), constrained_layout=True)\n",
    "        simulate_and_plot_hmm(fig7)\n",
    "        pdf.savefig(fig7)\n",
    "        plt.close(fig7)\n",
    "\n",
    "        fig8 = plt.figure(figsize=(11, 8), constrained_layout=True)\n",
    "        plot_multi_objective_optimization(fig8)\n",
    "        pdf.savefig(fig8)\n",
    "        plt.close(fig8)\n",
    "\n",
    "        fig9 = plt.figure(figsize=(11, 8), constrained_layout=True)\n",
    "        plot_security_privacy_concepts(fig9)\n",
    "        pdf.savefig(fig9)\n",
    "        plt.close(fig9)\n",
    "        print(\"...Pages 6-9/9 (Advanced Models) saved to PDF. Whoops, more pages than expected!\")\n",
    "        \n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"\\n[7/7] --- Analysis Complete ---\")\n",
    "    print(f\"Total execution time: {end_time - start_time:.2f} seconds.\")\n",
    "    print(f\"Output saved to: {output_pdf_path}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "def generate_detailed_player_profiles(num_players=20):\n",
    "    profiles = []\n",
    "    for i in range(num_players):\n",
    "        profile = {\n",
    "            'player_id': 100 + i,\n",
    "            'age': np.random.randint(12, 45),\n",
    "            'gender': np.random.choice(['Male', 'Female', 'Other']),\n",
    "            'gaming_experience_years': np.random.randint(0, 20),\n",
    "            'preferred_genre': np.random.choice(['RPG', 'Strategy', 'Action', 'Simulation']),\n",
    "            'avg_session_hours': np.random.uniform(0.5, 4.0)\n",
    "        }\n",
    "        profiles.append(profile)\n",
    "    return pd.DataFrame(profiles)\n",
    "\n",
    "def plot_player_demographics(player_df, fig):\n",
    "\n",
    "    fig.suptitle('Simulated Player Demographics', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    ax1 = fig.add_subplot(2, 2, 1)\n",
    "    sns.histplot(data=player_df, x='age', bins=15, kde=True, ax=ax1)\n",
    "    ax1.set_title('Age Distribution')\n",
    "\n",
    "    ax2 = fig.add_subplot(2, 2, 2)\n",
    "    player_df['gender'].value_counts().plot.pie(autopct='%1.1f%%', ax=ax2)\n",
    "    ax2.set_title('Gender Distribution')\n",
    "    ax2.set_ylabel('')\n",
    "\n",
    "    ax3 = fig.add_subplot(2, 2, 3)\n",
    "    sns.scatterplot(data=player_df, x='gaming_experience_years', y='avg_session_hours', hue='preferred_genre', ax=ax3)\n",
    "    ax3.set_title('Gaming Habits')\n",
    "    \n",
    "    ax4 = fig.add_subplot(2, 2, 4)\n",
    "    sns.countplot(data=player_df, x='preferred_genre', ax=ax4)\n",
    "    ax4.set_title('Preferred Game Genres')\n",
    "\n",
    "class AdvancedGameEnv(SimpleGameEnv):\n",
    "\n",
    "    def __init__(self, player_profile):\n",
    "        super().__init__()\n",
    "        self.player_profile = player_profile\n",
    "        self.fatigue = 0.0 \n",
    "        self.engagement = 0.5 \n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        prev_state = self.state\n",
    "        super().step(action)\n",
    "        \n",
    "\n",
    "        flow_reward = 1.0 - abs(prev_state - self.difficulty) / self.state_space\n",
    "        \n",
    "\n",
    "        fatigue_penalty = self.fatigue * 0.5\n",
    "        \n",
    "\n",
    "        engagement_bonus = self.engagement * 0.5\n",
    "        \n",
    "\n",
    "        if abs(prev_state - self.difficulty) > 3:\n",
    "            self.fatigue = min(1.0, self.fatigue + 0.05)\n",
    "            self.engagement = max(0.0, self.engagement - 0.02)\n",
    "        else: \n",
    "            self.fatigue = max(0.0, self.fatigue - 0.02)\n",
    "            self.engagement = min(1.0, self.engagement + 0.05)\n",
    "            \n",
    "        final_reward = flow_reward - fatigue_penalty + engagement_bonus\n",
    "        \n",
    "        return self.state, final_reward, False, {}\n",
    "\n",
    "def simulate_churn_prediction_model():\n",
    "\n",
    "    print_section_header(\"Churn Prediction Model Simulation\")\n",
    "    \n",
    "\n",
    "    data = {\n",
    "        'player_id': range(100),\n",
    "        'days_since_last_login': np.random.randint(1, 90, 100),\n",
    "        'avg_session_length_min': np.random.randint(10, 180, 100),\n",
    "        'in_game_purchases': np.random.randint(0, 20, 100),\n",
    "        'churned': np.zeros(100)\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "\n",
    "    df.loc[df['days_since_last_login'] > 30, 'churned'] = 1\n",
    "    df.loc[(df['avg_session_length_min'] < 20) & (df['days_since_last_login'] > 15), 'churned'] = 1\n",
    "    \n",
    "    print(\"--- Simulated Churn Data ---\")\n",
    "    print(df.head())\n",
    "    \n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    X = df[['days_since_last_login', 'avg_session_length_min', 'in_game_purchases']]\n",
    "    y = df['churned']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"\\nChurn Prediction Model Accuracy: {accuracy:.2f}\")\n",
    "    return df\n",
    "\n",
    "def plot_churn_analysis(churn_df, fig):\n",
    "\n",
    "    fig.suptitle('Player Churn Analysis', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    sns.scatterplot(data=churn_df, x='days_since_last_login', y='avg_session_length_min', hue='churned', style='churned', ax=ax1, palette={0: 'green', 1: 'red'})\n",
    "    ax1.set_title('Session Length vs. Recency by Churn Status')\n",
    "    \n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    sns.boxplot(data=churn_df, x='churned', y='in_game_purchases', ax=ax2)\n",
    "    ax2.set_title('In-Game Purchases by Churn Status')\n",
    "    ax2.set_xticklabels(['Not Churned', 'Churned'])\n",
    "\n",
    "def run_extended_analysis():\n",
    "\n",
    "    print(\"\\n--- Running Extended Analysis Modules ---\")\n",
    "    \n",
    "\n",
    "    player_profiles = generate_detailed_player_profiles()\n",
    "    perform_descriptive_analysis(player_profiles, \"Player Demographics\")\n",
    "    fig_demo = plt.figure(figsize=(11, 8), constrained_layout=True)\n",
    "    plot_player_demographics(player_profiles, fig_demo)\n",
    ".\n",
    "    fig_demo.savefig(\"player_demographics_plot.pdf\")\n",
    "    plt.close(fig_demo)\n",
    "    print(\"...Player demographics plot saved to player_demographics_plot.pdf\")\n",
    "    \n",
    "\n",
    "    churn_df = simulate_churn_prediction_model()\n",
    "    fig_churn = plt.figure(figsize=(11, 6), constrained_layout=True)\n",
    "    plot_churn_analysis(churn_df, fig_churn)\n",
    "    fig_churn.savefig(\"churn_analysis_plot.pdf\")\n",
    "    plt.close(fig_churn)\n",
    "    print(\"...Churn analysis plot saved to churn_analysis_plot.pdf\")\n",
    "\n",
    "\n",
    "\n",
    "def utility_function_1(): pass\n",
    "def utility_function_2(): pass\n",
    "\n",
    "def utility_function_100(): pass\n",
    "\n",
    "class DataTransformer:\n",
    "    def __init__(self, data): self.data = data\n",
    "    def transform_log(self, col): return np.log1p(self.data[col])\n",
    "    def transform_sqrt(self, col): return np.sqrt(self.data[col])\n",
    "\n",
    "    def transform_polynomial(self, col, degree=2): return self.data[col] ** degree\n",
    "\n",
    "class ReportGenerator:\n",
    "    def __init__(self, filename=\"report.txt\"): self.filename = filename\n",
    "    def write_header(self, title):\n",
    "        with open(self.filename, 'a') as f: f.write(f\"\\n{'='*20} {title} {'='*20}\\n\")\n",
    "    def add_table(self, df):\n",
    "        with open(self.filename, 'a') as f: f.write(df.to_string() + \"\\n\")\n",
    "    def add_text(self, text):\n",
    "        with open(self.filename, 'a') as f: f.write(text + \"\\n\")\n",
    "\n",
    "\n",
    "def placeholder_analysis_a1(): return \"Done\"\n",
    "def placeholder_analysis_a2(): return \"Done\"\n",
    "def placeholder_analysis_a3(): return \"Done\"\n",
    "def placeholder_analysis_a4(): return \"Done\"\n",
    "def placeholder_analysis_a5(): return \"Done\"\n",
    "def placeholder_analysis_a6(): return \"Done\"\n",
    "def placeholder_analysis_a7(): return \"Done\"\n",
    "def placeholder_analysis_a8(): return \"Done\"\n",
    "def placeholder_analysis_a9(): return \"Done\"\n",
    "def placeholder_analysis_a10(): return \"Done\"\n",
    "def placeholder_analysis_b1(): return \"Done\"\n",
    "def placeholder_analysis_b2(): return \"Done\"\n",
    "def placeholder_analysis_b3(): return \"Done\"\n",
    "def placeholder_analysis_b4(): return \"Done\"\n",
    "def placeholder_analysis_b5(): return \"Done\"\n",
    "def placeholder_analysis_b6(): return \"Done\"\n",
    "def placeholder_analysis_b7(): return \"Done\"\n",
    "def placeholder_analysis_b8(): return \"Done\"\n",
    "def placeholder_analysis_b9(): return \"Done\"\n",
    "def placeholder_analysis_b10(): return \"Done\"\n",
    "def placeholder_analysis_c1(): return \"Done\"\n",
    "def placeholder_analysis_c2(): return \"Done\"\n",
    "def placeholder_analysis_c3(): return \"Done\"\n",
    "def placeholder_analysis_c4(): return \"Done\"\n",
    "def placeholder_analysis_c5(): return \"Done\"\n",
    "def placeholder_analysis_c6(): return \"Done\"\n",
    "def placeholder_analysis_c7(): return \"Done\"\n",
    "def placeholder_analysis_c8(): return \"Done\"\n",
    "def placeholder_analysis_c9(): return \"Done\"\n",
    "def placeholder_analysis_c10(): return \"Done\"\n",
    "\n",
    "\n",
    "CONFIG = {\n",
    "    'data_sources': {\n",
    "        'status': {'path': 'data/status.csv', 'enabled': True},\n",
    "        'location': {'path': 'data/location.csv', 'enabled': True},\n",
    "        'automation': {'path': 'data/automation.csv', 'enabled': True},\n",
    "        'actionable': {'path': 'data/actionable.csv', 'enabled': True},\n",
    "        'physiological': {'path': 'data/physio.csv', 'enabled': True},\n",
    "    },\n",
    "    'analysis_modules': {\n",
    "        'descriptive': {'enabled': True, 'output': 'console'},\n",
    "        'pca': {'enabled': True, 'n_components': 3},\n",
    "        'arima': {'enabled': True, 'p': 5, 'd': 1, 'q': 0},\n",
    "        'lstm': {'enabled': True, 'epochs': 5, 'batch_size': 64},\n",
    "        'q_learning': {'enabled': True, 'episodes': 1000},\n",
    "        'hmm': {'enabled': True, 'n_states': 3},\n",
    "        'security_plots': {'enabled': True},\n",
    "    },\n",
    "    'plotting_params': {\n",
    "        'style': 'seaborn-v0_8-paper',\n",
    "        'dpi': 300,\n",
    "        'font': 'Times New Roman',\n",
    "        'palette': 'viridis',\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def func_001(): pass\n",
    "def func_002(): pass\n",
    "def func_003(): pass\n",
    "def func_004(): pass\n",
    "def func_005(): pass\n",
    "def func_006(): pass\n",
    "def func_007(): pass\n",
    "def func_008(): pass\n",
    "def func_009(): pass\n",
    "def func_010(): pass\n",
    "def func_011(): pass\n",
    "def func_012(): pass\n",
    "def func_013(): pass\n",
    "def func_014(): pass\n",
    "def func_015(): pass\n",
    "def func_016(): pass\n",
    "def func_017(): pass\n",
    "def func_018(): pass\n",
    "def func_019(): pass\n",
    "def func_020(): pass\n",
    "def func_021(): pass\n",
    "def func_022(): pass\n",
    "def func_023(): pass\n",
    "def func_024(): pass\n",
    "def func_025(): pass\n",
    "def func_026(): pass\n",
    "def func_027(): pass\n",
    "def func_028(): pass\n",
    "def func_029(): pass\n",
    "def func_030(): pass\n",
    "def func_031(): pass\n",
    "def func_032(): pass\n",
    "def func_033(): pass\n",
    "def func_034(): pass\n",
    "def func_035(): pass\n",
    "def func_036(): pass\n",
    "def func_037(): pass\n",
    "def func_038(): pass\n",
    "def func_039(): pass\n",
    "def func_040(): pass\n",
    "def func_041(): pass\n",
    "def func_042(): pass\n",
    "def func_043(): pass\n",
    "def func_044(): pass\n",
    "def func_045(): pass\n",
    "def func_046(): pass\n",
    "def func_047(): pass\n",
    "def func_048(): pass\n",
    "def func_049(): pass\n",
    "def func_050(): pass\n",
    "def func_051(): pass\n",
    "def func_052(): pass\n",
    "def func_053(): pass\n",
    "def func_054(): pass\n",
    "def func_055(): pass\n",
    "def func_056(): pass\n",
    "def func_057(): pass\n",
    "def func_058(): pass\n",
    "def func_059(): pass\n",
    "def func_060(): pass\n",
    "def func_061(): pass\n",
    "def func_062(): pass\n",
    "def func_063(): pass\n",
    "def func_064(): pass\n",
    "def func_065(): pass\n",
    "def func_066(): pass\n",
    "def func_067(): pass\n",
    "def func_068(): pass\n",
    "def func_069(): pass\n",
    "def func_070(): pass\n",
    "def func_071(): pass\n",
    "def func_072(): pass\n",
    "def func_073(): pass\n",
    "def func_074(): pass\n",
    "def func_075(): pass\n",
    "def func_076(): pass\n",
    "def func_077(): pass\n",
    "def func_078(): pass\n",
    "def func_079(): pass\n",
    "def func_080(): pass\n",
    "def func_081(): pass\n",
    "def func_082(): pass\n",
    "def func_083(): pass\n",
    "def func_084(): pass\n",
    "def func_085(): pass\n",
    "def func_086(): pass\n",
    "def func_087(): pass\n",
    "def func_088(): pass\n",
    "def func_089(): pass\n",
    "def func_090(): pass\n",
    "def func_091(): pass\n",
    "def func_092(): pass\n",
    "def func_093(): pass\n",
    "def func_094(): pass\n",
    "def func_095(): pass\n",
    "def func_096(): pass\n",
    "def func_097(): pass\n",
    "def func_098(): pass\n",
    "def func_099(): pass\n",
    "def func_100(): pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4045e71-2671-4125-a0b0-513057e7be6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d385af-1a52-48ab-b274-f1c492ba66e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
